{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "REID_DEMO.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8f8088eeff964d1bace95607ee419774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a9f5dfd2f8f54377b890f33299fa290a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_142214bc130943debca920b8d1c5a56e",
              "IPY_MODEL_003314ccf4694080bf4b8b5fab8e3b36",
              "IPY_MODEL_e3702fa49e3948bd9dc69a1120a7b8d7"
            ]
          }
        },
        "a9f5dfd2f8f54377b890f33299fa290a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "142214bc130943debca920b8d1c5a56e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e2f97dc8fdfa4c88b2d9bef78852b269",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c407748413174f4a971327f7bc939744"
          }
        },
        "003314ccf4694080bf4b8b5fab8e3b36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6b3eaf05baaf44eb919e07549fc1ae9d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46830571,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46830571,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_24bcf124f9494541993a0d7975fecad4"
          }
        },
        "e3702fa49e3948bd9dc69a1120a7b8d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e9014cf6f5ce4fa582793a8c5d833bcd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 150MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b0eafe0e290649e8ba0cf8ae1033e41c"
          }
        },
        "e2f97dc8fdfa4c88b2d9bef78852b269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c407748413174f4a971327f7bc939744": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6b3eaf05baaf44eb919e07549fc1ae9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "24bcf124f9494541993a0d7975fecad4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9014cf6f5ce4fa582793a8c5d833bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b0eafe0e290649e8ba0cf8ae1033e41c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHPNQ0C7YNtv",
        "outputId": "4cfe4467-cc3c-48be-a352-0bd3c2da6c99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Neural Network & Deep Learning\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "%cd /content/drive/My Drive/Neural Network & Deep Learning/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import glob\n",
        "import random\n",
        "from torchsummary import summary\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from prefetch_generator import BackgroundGenerator\n",
        "from torch.autograd import Variable\n",
        "import torch.backends.cudnn as cudnn\n",
        "from collections import defaultdict\n",
        "from math import sqrt\n",
        "from functools import reduce\n",
        "import numpy as np\n",
        "import math\n",
        "from PIL import Image\n",
        "cudnn.enabled = True\n",
        "cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "JBYyFpqWd1Gq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Have a look at the original resnet18 first"
      ],
      "metadata": {
        "id": "GZTRtz_Tfm-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "res18 = models.resnet18().cuda()\n",
        "res18.layer4[0].conv1 = nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, device=\"cuda:0\")\n",
        "res18.layer4[0].downsample[0] = nn.Conv2d(256, 512, kernel_size=(1,1), stride=(1,1), bias=False, device=\"cuda:0\")\n",
        "summary(res18, input_size=(3,128,64))\n",
        "# res18"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svgHjxJofqaJ",
        "outputId": "35c74dd9-fe3a-47e7-c0cc-2547ee863f5f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 64, 32]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 64, 32]             128\n",
            "              ReLU-3           [-1, 64, 64, 32]               0\n",
            "         MaxPool2d-4           [-1, 64, 32, 16]               0\n",
            "            Conv2d-5           [-1, 64, 32, 16]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 32, 16]             128\n",
            "              ReLU-7           [-1, 64, 32, 16]               0\n",
            "            Conv2d-8           [-1, 64, 32, 16]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 32, 16]             128\n",
            "             ReLU-10           [-1, 64, 32, 16]               0\n",
            "       BasicBlock-11           [-1, 64, 32, 16]               0\n",
            "           Conv2d-12           [-1, 64, 32, 16]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 32, 16]             128\n",
            "             ReLU-14           [-1, 64, 32, 16]               0\n",
            "           Conv2d-15           [-1, 64, 32, 16]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 32, 16]             128\n",
            "             ReLU-17           [-1, 64, 32, 16]               0\n",
            "       BasicBlock-18           [-1, 64, 32, 16]               0\n",
            "           Conv2d-19           [-1, 128, 16, 8]          73,728\n",
            "      BatchNorm2d-20           [-1, 128, 16, 8]             256\n",
            "             ReLU-21           [-1, 128, 16, 8]               0\n",
            "           Conv2d-22           [-1, 128, 16, 8]         147,456\n",
            "      BatchNorm2d-23           [-1, 128, 16, 8]             256\n",
            "           Conv2d-24           [-1, 128, 16, 8]           8,192\n",
            "      BatchNorm2d-25           [-1, 128, 16, 8]             256\n",
            "             ReLU-26           [-1, 128, 16, 8]               0\n",
            "       BasicBlock-27           [-1, 128, 16, 8]               0\n",
            "           Conv2d-28           [-1, 128, 16, 8]         147,456\n",
            "      BatchNorm2d-29           [-1, 128, 16, 8]             256\n",
            "             ReLU-30           [-1, 128, 16, 8]               0\n",
            "           Conv2d-31           [-1, 128, 16, 8]         147,456\n",
            "      BatchNorm2d-32           [-1, 128, 16, 8]             256\n",
            "             ReLU-33           [-1, 128, 16, 8]               0\n",
            "       BasicBlock-34           [-1, 128, 16, 8]               0\n",
            "           Conv2d-35            [-1, 256, 8, 4]         294,912\n",
            "      BatchNorm2d-36            [-1, 256, 8, 4]             512\n",
            "             ReLU-37            [-1, 256, 8, 4]               0\n",
            "           Conv2d-38            [-1, 256, 8, 4]         589,824\n",
            "      BatchNorm2d-39            [-1, 256, 8, 4]             512\n",
            "           Conv2d-40            [-1, 256, 8, 4]          32,768\n",
            "      BatchNorm2d-41            [-1, 256, 8, 4]             512\n",
            "             ReLU-42            [-1, 256, 8, 4]               0\n",
            "       BasicBlock-43            [-1, 256, 8, 4]               0\n",
            "           Conv2d-44            [-1, 256, 8, 4]         589,824\n",
            "      BatchNorm2d-45            [-1, 256, 8, 4]             512\n",
            "             ReLU-46            [-1, 256, 8, 4]               0\n",
            "           Conv2d-47            [-1, 256, 8, 4]         589,824\n",
            "      BatchNorm2d-48            [-1, 256, 8, 4]             512\n",
            "             ReLU-49            [-1, 256, 8, 4]               0\n",
            "       BasicBlock-50            [-1, 256, 8, 4]               0\n",
            "           Conv2d-51            [-1, 512, 8, 4]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 8, 4]           1,024\n",
            "             ReLU-53            [-1, 512, 8, 4]               0\n",
            "           Conv2d-54            [-1, 512, 8, 4]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 8, 4]           1,024\n",
            "           Conv2d-56            [-1, 512, 8, 4]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 8, 4]           1,024\n",
            "             ReLU-58            [-1, 512, 8, 4]               0\n",
            "       BasicBlock-59            [-1, 512, 8, 4]               0\n",
            "           Conv2d-60            [-1, 512, 8, 4]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 8, 4]           1,024\n",
            "             ReLU-62            [-1, 512, 8, 4]               0\n",
            "           Conv2d-63            [-1, 512, 8, 4]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 8, 4]           1,024\n",
            "             ReLU-65            [-1, 512, 8, 4]               0\n",
            "       BasicBlock-66            [-1, 512, 8, 4]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                 [-1, 1000]         513,000\n",
            "================================================================\n",
            "Total params: 11,689,512\n",
            "Trainable params: 11,689,512\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.09\n",
            "Forward/backward pass size (MB): 11.76\n",
            "Params size (MB): 44.59\n",
            "Estimated Total Size (MB): 56.45\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoaderX(DataLoader):\n",
        "    def __iter__(self):\n",
        "        return BackgroundGenerator(super().__iter__())"
      ],
      "metadata": {
        "id": "pdXgZkalEtYT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not know if the last layer for the embedding needs normalization"
      ],
      "metadata": {
        "id": "guS_8TkH5gdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, c_in):\n",
        "        super().__init__()\n",
        "        self.globalavgpooling = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc1 = nn.Linear(c_in, max(1, c_in // 16))\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.fc2 = nn.Linear(max(1, c_in // 16), c_in)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.c_in = c_in\n",
        "    \n",
        "    def forward(self, x):\n",
        "        assert self.c_in == x.size(1)\n",
        "        x = self.globalavgpooling(x)\n",
        "        x = x.squeeze()\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = x.unsqueeze(-1).unsqueeze(-1)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SEDense18(nn.Module):\n",
        "    def __init__(self, num_class=751, needs_norm=True, is_reid=False):\n",
        "        super().__init__()\n",
        "        model = models.resnet18(pretrained=True)\n",
        "        self.conv0 = model.conv1\n",
        "        self.bn0 = model.bn1\n",
        "        self.relu0 = model.relu\n",
        "        self.pooling0 = model.maxpool\n",
        "        self.basicBlock11 = model.layer1[0]\n",
        "        self.seblock1 = SEBlock(64)\n",
        "\n",
        "        self.basicBlock12 = model.layer1[1]\n",
        "        self.seblock2 = SEBlock(64)\n",
        "\n",
        "        self.basicBlock21 = model.layer2[0]\n",
        "        self.seblock3 = SEBlock(128)\n",
        "        self.ancillaryconv3 = nn.Conv2d(64, 128, 1, 2, 0)\n",
        "        self.optionalNorm2dconv3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.basicBlock22 = model.layer2[1]\n",
        "        self.seblock4 = SEBlock(128)\n",
        "\n",
        "        self.basicBlock31 = model.layer3[0]\n",
        "        self.seblock5 = SEBlock(256)\n",
        "        self.ancillaryconv5 = nn.Conv2d(128, 256, 1, 2, 0)\n",
        "        self.optionalNorm2dconv5 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.basicBlock32 = model.layer3[1]\n",
        "        self.seblock6 = SEBlock(256)\n",
        "\n",
        "        self.basicBlock41 = model.layer4[0]\n",
        "        # last stride = 1\n",
        "        self.basicBlock41.conv1 = nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, device=\"cuda:0\")\n",
        "        self.basicBlock41.downsample[0] = nn.Conv2d(256, 512, kernel_size=(1,1), stride=(1,1), bias=False, device=\"cuda:0\")\n",
        "        self.seblock7 = SEBlock(512)\n",
        "        self.ancillaryconv7 = nn.Conv2d(256, 512, 1, 1, 0)\n",
        "        self.optionalNorm2dconv7 = nn.BatchNorm2d(512)\n",
        "\n",
        "        self.basicBlock42 = model.layer4[1]\n",
        "        self.seblock8 = SEBlock(512)\n",
        "\n",
        "        self.avgpooling = model.avgpool\n",
        "        # self.fc = nn.Linear(512, num_class)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256, num_class),\n",
        "        )\n",
        "        self.needs_norm = needs_norm\n",
        "        self.is_reid = is_reid\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv0(x)\n",
        "        x = self.bn0(x)\n",
        "        x = self.relu0(x)\n",
        "        x = self.pooling0(x)\n",
        "        branch1 = x\n",
        "        x = self.basicBlock11(x)\n",
        "        scale1 = self.seblock1(x)\n",
        "        x = scale1 * x + branch1\n",
        "\n",
        "        branch2 = x\n",
        "        x = self.basicBlock12(x)\n",
        "        scale2 = self.seblock2(x)\n",
        "        x = scale2 * x + branch2\n",
        "\n",
        "        branch3 = x\n",
        "        x = self.basicBlock21(x)\n",
        "        scale3 = self.seblock3(x)\n",
        "        if self.needs_norm:\n",
        "            x = scale3 * x + self.optionalNorm2dconv3(self.ancillaryconv3(branch3))\n",
        "        else:\n",
        "            x = scale3 * x + self.ancillaryconv3(branch3)\n",
        "\n",
        "        branch4 = x\n",
        "        x = self.basicBlock22(x)\n",
        "        scale4 = self.seblock4(x)\n",
        "        x = scale4 * x + branch4\n",
        "\n",
        "        branch5 = x\n",
        "        x = self.basicBlock31(x)\n",
        "        scale5 = self.seblock5(x)\n",
        "        if self.needs_norm:\n",
        "            x = scale5 * x + self.optionalNorm2dconv5(self.ancillaryconv5(branch5))\n",
        "        else:\n",
        "            x = scale5 * x + self.ancillaryconv5(branch5)\n",
        "\n",
        "        branch6 = x\n",
        "        x = self.basicBlock32(x)\n",
        "        scale6 = self.seblock6(x)\n",
        "        x = scale6 * x + branch6\n",
        "\n",
        "        branch7 = x\n",
        "        x = self.basicBlock41(x)\n",
        "        scale7 = self.seblock7(x)\n",
        "        if self.needs_norm:\n",
        "            x = scale7 * x + self.optionalNorm2dconv7(self.ancillaryconv7(branch7))\n",
        "        else:\n",
        "            x = scale7 * x + self.ancillaryconv7(branch7)\n",
        "\n",
        "        branch8 = x\n",
        "        x = self.basicBlock42(x)\n",
        "        scale8 = self.seblock8(x)\n",
        "        x = scale8 * x + branch8\n",
        "\n",
        "        x = self.avgpooling(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        if self.is_reid:\n",
        "            return x\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "my_model = SEDense18().cuda()\n",
        "summary(my_model, input_size=(3, 128, 64))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8f8088eeff964d1bace95607ee419774",
            "a9f5dfd2f8f54377b890f33299fa290a",
            "142214bc130943debca920b8d1c5a56e",
            "003314ccf4694080bf4b8b5fab8e3b36",
            "e3702fa49e3948bd9dc69a1120a7b8d7",
            "e2f97dc8fdfa4c88b2d9bef78852b269",
            "c407748413174f4a971327f7bc939744",
            "6b3eaf05baaf44eb919e07549fc1ae9d",
            "24bcf124f9494541993a0d7975fecad4",
            "e9014cf6f5ce4fa582793a8c5d833bcd",
            "b0eafe0e290649e8ba0cf8ae1033e41c"
          ]
        },
        "id": "wcgXv43eYkAu",
        "outputId": "ab5150bf-d483-490c-c0f9-847e58f2ce04"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f8088eeff964d1bace95607ee419774",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 64, 32]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 64, 32]             128\n",
            "              ReLU-3           [-1, 64, 64, 32]               0\n",
            "         MaxPool2d-4           [-1, 64, 32, 16]               0\n",
            "            Conv2d-5           [-1, 64, 32, 16]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 32, 16]             128\n",
            "              ReLU-7           [-1, 64, 32, 16]               0\n",
            "            Conv2d-8           [-1, 64, 32, 16]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 32, 16]             128\n",
            "             ReLU-10           [-1, 64, 32, 16]               0\n",
            "       BasicBlock-11           [-1, 64, 32, 16]               0\n",
            "AdaptiveAvgPool2d-12             [-1, 64, 1, 1]               0\n",
            "           Linear-13                    [-1, 4]             260\n",
            "             ReLU-14                    [-1, 4]               0\n",
            "           Linear-15                   [-1, 64]             320\n",
            "          Sigmoid-16             [-1, 64, 1, 1]               0\n",
            "          SEBlock-17             [-1, 64, 1, 1]               0\n",
            "           Conv2d-18           [-1, 64, 32, 16]          36,864\n",
            "      BatchNorm2d-19           [-1, 64, 32, 16]             128\n",
            "             ReLU-20           [-1, 64, 32, 16]               0\n",
            "           Conv2d-21           [-1, 64, 32, 16]          36,864\n",
            "      BatchNorm2d-22           [-1, 64, 32, 16]             128\n",
            "             ReLU-23           [-1, 64, 32, 16]               0\n",
            "       BasicBlock-24           [-1, 64, 32, 16]               0\n",
            "AdaptiveAvgPool2d-25             [-1, 64, 1, 1]               0\n",
            "           Linear-26                    [-1, 4]             260\n",
            "             ReLU-27                    [-1, 4]               0\n",
            "           Linear-28                   [-1, 64]             320\n",
            "          Sigmoid-29             [-1, 64, 1, 1]               0\n",
            "          SEBlock-30             [-1, 64, 1, 1]               0\n",
            "           Conv2d-31           [-1, 128, 16, 8]          73,728\n",
            "      BatchNorm2d-32           [-1, 128, 16, 8]             256\n",
            "             ReLU-33           [-1, 128, 16, 8]               0\n",
            "           Conv2d-34           [-1, 128, 16, 8]         147,456\n",
            "      BatchNorm2d-35           [-1, 128, 16, 8]             256\n",
            "           Conv2d-36           [-1, 128, 16, 8]           8,192\n",
            "      BatchNorm2d-37           [-1, 128, 16, 8]             256\n",
            "             ReLU-38           [-1, 128, 16, 8]               0\n",
            "       BasicBlock-39           [-1, 128, 16, 8]               0\n",
            "AdaptiveAvgPool2d-40            [-1, 128, 1, 1]               0\n",
            "           Linear-41                    [-1, 8]           1,032\n",
            "             ReLU-42                    [-1, 8]               0\n",
            "           Linear-43                  [-1, 128]           1,152\n",
            "          Sigmoid-44            [-1, 128, 1, 1]               0\n",
            "          SEBlock-45            [-1, 128, 1, 1]               0\n",
            "           Conv2d-46           [-1, 128, 16, 8]           8,320\n",
            "      BatchNorm2d-47           [-1, 128, 16, 8]             256\n",
            "           Conv2d-48           [-1, 128, 16, 8]         147,456\n",
            "      BatchNorm2d-49           [-1, 128, 16, 8]             256\n",
            "             ReLU-50           [-1, 128, 16, 8]               0\n",
            "           Conv2d-51           [-1, 128, 16, 8]         147,456\n",
            "      BatchNorm2d-52           [-1, 128, 16, 8]             256\n",
            "             ReLU-53           [-1, 128, 16, 8]               0\n",
            "       BasicBlock-54           [-1, 128, 16, 8]               0\n",
            "AdaptiveAvgPool2d-55            [-1, 128, 1, 1]               0\n",
            "           Linear-56                    [-1, 8]           1,032\n",
            "             ReLU-57                    [-1, 8]               0\n",
            "           Linear-58                  [-1, 128]           1,152\n",
            "          Sigmoid-59            [-1, 128, 1, 1]               0\n",
            "          SEBlock-60            [-1, 128, 1, 1]               0\n",
            "           Conv2d-61            [-1, 256, 8, 4]         294,912\n",
            "      BatchNorm2d-62            [-1, 256, 8, 4]             512\n",
            "             ReLU-63            [-1, 256, 8, 4]               0\n",
            "           Conv2d-64            [-1, 256, 8, 4]         589,824\n",
            "      BatchNorm2d-65            [-1, 256, 8, 4]             512\n",
            "           Conv2d-66            [-1, 256, 8, 4]          32,768\n",
            "      BatchNorm2d-67            [-1, 256, 8, 4]             512\n",
            "             ReLU-68            [-1, 256, 8, 4]               0\n",
            "       BasicBlock-69            [-1, 256, 8, 4]               0\n",
            "AdaptiveAvgPool2d-70            [-1, 256, 1, 1]               0\n",
            "           Linear-71                   [-1, 16]           4,112\n",
            "             ReLU-72                   [-1, 16]               0\n",
            "           Linear-73                  [-1, 256]           4,352\n",
            "          Sigmoid-74            [-1, 256, 1, 1]               0\n",
            "          SEBlock-75            [-1, 256, 1, 1]               0\n",
            "           Conv2d-76            [-1, 256, 8, 4]          33,024\n",
            "      BatchNorm2d-77            [-1, 256, 8, 4]             512\n",
            "           Conv2d-78            [-1, 256, 8, 4]         589,824\n",
            "      BatchNorm2d-79            [-1, 256, 8, 4]             512\n",
            "             ReLU-80            [-1, 256, 8, 4]               0\n",
            "           Conv2d-81            [-1, 256, 8, 4]         589,824\n",
            "      BatchNorm2d-82            [-1, 256, 8, 4]             512\n",
            "             ReLU-83            [-1, 256, 8, 4]               0\n",
            "       BasicBlock-84            [-1, 256, 8, 4]               0\n",
            "AdaptiveAvgPool2d-85            [-1, 256, 1, 1]               0\n",
            "           Linear-86                   [-1, 16]           4,112\n",
            "             ReLU-87                   [-1, 16]               0\n",
            "           Linear-88                  [-1, 256]           4,352\n",
            "          Sigmoid-89            [-1, 256, 1, 1]               0\n",
            "          SEBlock-90            [-1, 256, 1, 1]               0\n",
            "           Conv2d-91            [-1, 512, 8, 4]       1,179,648\n",
            "      BatchNorm2d-92            [-1, 512, 8, 4]           1,024\n",
            "             ReLU-93            [-1, 512, 8, 4]               0\n",
            "           Conv2d-94            [-1, 512, 8, 4]       2,359,296\n",
            "      BatchNorm2d-95            [-1, 512, 8, 4]           1,024\n",
            "           Conv2d-96            [-1, 512, 8, 4]         131,072\n",
            "      BatchNorm2d-97            [-1, 512, 8, 4]           1,024\n",
            "             ReLU-98            [-1, 512, 8, 4]               0\n",
            "       BasicBlock-99            [-1, 512, 8, 4]               0\n",
            "AdaptiveAvgPool2d-100            [-1, 512, 1, 1]               0\n",
            "          Linear-101                   [-1, 32]          16,416\n",
            "            ReLU-102                   [-1, 32]               0\n",
            "          Linear-103                  [-1, 512]          16,896\n",
            "         Sigmoid-104            [-1, 512, 1, 1]               0\n",
            "         SEBlock-105            [-1, 512, 1, 1]               0\n",
            "          Conv2d-106            [-1, 512, 8, 4]         131,584\n",
            "     BatchNorm2d-107            [-1, 512, 8, 4]           1,024\n",
            "          Conv2d-108            [-1, 512, 8, 4]       2,359,296\n",
            "     BatchNorm2d-109            [-1, 512, 8, 4]           1,024\n",
            "            ReLU-110            [-1, 512, 8, 4]               0\n",
            "          Conv2d-111            [-1, 512, 8, 4]       2,359,296\n",
            "     BatchNorm2d-112            [-1, 512, 8, 4]           1,024\n",
            "            ReLU-113            [-1, 512, 8, 4]               0\n",
            "      BasicBlock-114            [-1, 512, 8, 4]               0\n",
            "AdaptiveAvgPool2d-115            [-1, 512, 1, 1]               0\n",
            "          Linear-116                   [-1, 32]          16,416\n",
            "            ReLU-117                   [-1, 32]               0\n",
            "          Linear-118                  [-1, 512]          16,896\n",
            "         Sigmoid-119            [-1, 512, 1, 1]               0\n",
            "         SEBlock-120            [-1, 512, 1, 1]               0\n",
            "AdaptiveAvgPool2d-121            [-1, 512, 1, 1]               0\n",
            "          Linear-122                  [-1, 256]         131,328\n",
            "     BatchNorm1d-123                  [-1, 256]             512\n",
            "            ReLU-124                  [-1, 256]               0\n",
            "         Dropout-125                  [-1, 256]               0\n",
            "          Linear-126                  [-1, 751]         193,007\n",
            "================================================================\n",
            "Total params: 11,765,159\n",
            "Trainable params: 11,765,159\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.09\n",
            "Forward/backward pass size (MB): 12.45\n",
            "Params size (MB): 44.88\n",
            "Estimated Total Size (MB): 57.43\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, image_path, pose_path, label_path, transform):\n",
        "        super().__init__()\n",
        "        self.image_path = image_path\n",
        "        self.pose_path = pose_path\n",
        "        self.label_path = label_path\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.image_path)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image1 = self.image_path[idx]\n",
        "        pose1 = self.pose_path[idx]\n",
        "        random_index = random.choice([i for i in range(len(self.image_path)) if i != idx])\n",
        "        image2 = self.image_path[random_index]\n",
        "        pose2 = self.pose_path[random_index]\n",
        "        relative_label = 0 if self.label_path[idx] == self.label_path[random_index] else 1\n",
        "        absolute_label = self.label_path[idx]\n",
        "        image1 = Image.open(image1).convert(\"RGB\")\n",
        "        image2 = Image.open(image2).convert(\"RGB\")\n",
        "        pose1 = transforms.ToTensor()(Image.open(pose1).convert(\"L\"))\n",
        "        pose2 = transforms.ToTensor()(Image.open(pose2).convert(\"L\"))\n",
        "        if self.transform:\n",
        "            image1 = self.transform(image1)\n",
        "            image2 = self.transform(image2)\n",
        "        relative_label = torch.tensor(relative_label).int()\n",
        "        absolute_label = torch.tensor(absolute_label).int()\n",
        "        return image1, image2, pose1, pose2, relative_label, absolute_label\n",
        "\n",
        "\n",
        "class CenTriDataset(Dataset):\n",
        "    def __init__(self, image_path, label_path, transform):\n",
        "        self.image_path = image_path\n",
        "        self.label_path = label_path\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.image_path)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image = self.image_path[idx]\n",
        "        label = self.label_path[idx]\n",
        "        image = Image.open(image).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(label).int()\n",
        "\n",
        "\n",
        "def relabel(label_set):\n",
        "    label = 0\n",
        "    latest_label = label_set[0]\n",
        "    new_label_set = list()\n",
        "    for cur_label in label_set:\n",
        "        if cur_label != latest_label:\n",
        "            label += 1\n",
        "            latest_label = cur_label\n",
        "        new_label_set.append(label)\n",
        "    return new_label_set"
      ],
      "metadata": {
        "id": "O8nJr2Q1dwhh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class contrastiveLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Contrastive loss function.\n",
        "    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, margin=20.0):\n",
        "        super(contrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
        "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
        "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "        return loss_contrastive\n",
        "\n",
        "\n",
        "class LabelSmoothing(nn.Module):\n",
        "    \"\"\" NLL loss with label smoothing. \"\"\"\n",
        "\n",
        "    def __init__(self, smoothing=0.1):\n",
        "        \"\"\" Constructor for the LabelSmoothing module.\n",
        "        :param smoothing: label smoothing factor \"\"\"\n",
        "        super(LabelSmoothing, self).__init__()\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "\n",
        "    def forward(self, x, target):\n",
        "        logprobs = torch.nn.functional.log_softmax(x, dim=-1)\n",
        "        target = target.long()\n",
        "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
        "        nll_loss = nll_loss.squeeze(1)\n",
        "        smooth_loss = -logprobs.mean(dim=-1)\n",
        "        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
        "        return loss.mean()\n",
        "\n"
      ],
      "metadata": {
        "id": "D4tuCWA77Kbb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding center loss and triplet to train the network based on strong baseline paper."
      ],
      "metadata": {
        "id": "i-KUr3ZoRG_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CenterLoss(nn.Module):\n",
        "    \"\"\"Center loss.\n",
        "    Reference:\n",
        "    Wen et al. A Discriminative Feature Learning Approach for Deep Face Recognition. ECCV 2016.\n",
        "    Args:\n",
        "        num_classes (int): number of classes.\n",
        "        feat_dim (int): feature dimension.\n",
        "    \"\"\"\n",
        " \n",
        "    def __init__(self, num_classes=751, feat_dim=2048, use_gpu=True):\n",
        "        super(CenterLoss, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.feat_dim = feat_dim\n",
        "        self.use_gpu = use_gpu\n",
        " \n",
        "        if self.use_gpu:\n",
        "            self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim).cuda())\n",
        "        else:\n",
        "            self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim))\n",
        " \n",
        "    def forward(self, x, labels):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: feature matrix with shape (batch_size, feat_dim).\n",
        "            labels: ground truth labels with shape (num_classes).\n",
        "        \"\"\"\n",
        "        assert x.size(0) == labels.size(0), \"features.size(0) is not equal to labels.size(0)\"\n",
        " \n",
        "        batch_size = x.size(0)\n",
        "        distmat = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(batch_size, self.num_classes) + \\\n",
        "                  torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.num_classes, batch_size).t()\n",
        "        distmat.addmm_(1, -2, x, self.centers.t())\n",
        " \n",
        "        classes = torch.arange(self.num_classes).long()\n",
        "        if self.use_gpu: classes = classes.cuda()\n",
        "        labels = labels.unsqueeze(1).expand(batch_size, self.num_classes)\n",
        "        mask = labels.eq(classes.expand(batch_size, self.num_classes))\n",
        " \n",
        "        dist = []\n",
        "        for i in range(batch_size):\n",
        "            value = distmat[i][mask[i]]\n",
        "            value = value.clamp(min=1e-12, max=1e+12)  # for numerical stability\n",
        "            dist.append(value)\n",
        "        dist = torch.cat(dist)\n",
        "        loss = dist.mean()\n",
        "        return loss\n",
        "\n",
        "\n",
        "class TripletLoss(nn.Module):\n",
        "    \"\"\"Triplet loss with hard positive/negative mining.\n",
        "    \n",
        "    Reference:\n",
        "        Hermans et al. In Defense of the Triplet Loss for Person Re-Identification. arXiv:1703.07737.\n",
        "    \n",
        "    Imported from `<https://github.com/Cysu/open-reid/blob/master/reid/loss/triplet.py>`_.\n",
        "    \n",
        "    Args:\n",
        "        margin (float, optional): margin for triplet. Default is 0.3.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, margin=0.3):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "        self.ranking_loss = nn.MarginRankingLoss(margin=margin)\n",
        " \n",
        "    def forward(self, inputs, targets):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            inputs (torch.Tensor): feature matrix with shape (batch_size, feat_dim).\n",
        "            targets (torch.LongTensor): ground truth labels with shape (num_classes).\n",
        "        \"\"\"\n",
        "        n = inputs.size(0)\n",
        "        \n",
        "        # Compute pairwise distance, replace by the official when merged\n",
        "        dist = torch.pow(inputs, 2).sum(dim=1, keepdim=True).expand(n, n)\n",
        "        dist = dist + dist.t()\n",
        "        dist.addmm_(1, -2, inputs, inputs.t())\n",
        "        dist = dist.clamp(min=1e-12).sqrt()  # for numerical stability\n",
        "        \n",
        "        # For each anchor, find the hardest positive and negative\n",
        "        mask = targets.expand(n, n).eq(targets.expand(n, n).t())\n",
        "        dist_ap, dist_an = [], []\n",
        "        for i in range(n):\n",
        "            dist_ap.append(dist[i][mask[i]].max().unsqueeze(0))\n",
        "            dist_an.append(dist[i][mask[i] == 0].min().unsqueeze(0))\n",
        "        dist_ap = torch.cat(dist_ap)\n",
        "        dist_an = torch.cat(dist_an)\n",
        "        \n",
        "        # Compute ranking hinge loss\n",
        "        y = torch.ones_like(dist_an)\n",
        "        return self.ranking_loss(dist_an, dist_ap, y)"
      ],
      "metadata": {
        "id": "QTxROLe7RGhJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I find it hard to do strict contrastive training since for the same person, there may be pose issues."
      ],
      "metadata": {
        "id": "LM58WQta-KaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PoseLoss(nn.Module):\n",
        "    def __init__(self, margin=None):\n",
        "        super().__init__()\n",
        "    \n",
        "    def forward(self, pose1, pose2):\n",
        "        return torch.log(torch.clamp(torch.abs(torch.sum(pose1) - torch.sum(pose2)), 0.) + 1e-6)\n",
        "\n",
        "class HybridLoss(nn.Module):\n",
        "    def __init__(self, margin=20.0):\n",
        "        super().__init__()\n",
        "        self.contrastive = contrastiveLoss(margin)\n",
        "        self.pose = PoseLoss()\n",
        "    \n",
        "    def forward(self, feature1, feature2, label, pose1, pose2):\n",
        "        return self.contrastive(feature1, feature2, label) + 0.05 * self.pose(pose1, pose2)\n",
        "\n",
        "\n",
        "class HybridLoss2(nn.Module):\n",
        "    def __init__(self, num_classes, feat_dim=512, margin=50):\n",
        "        super().__init__()\n",
        "        self.center = CenterLoss(num_classes=num_classes, feat_dim=feat_dim)\n",
        "        self.triplet = TripletLoss(margin)\n",
        "    \n",
        "    def forward(self, features, targets):\n",
        "        \"\"\"\n",
        "        features: feature vectors\n",
        "        targets: ground truth labels\n",
        "        \"\"\"\n",
        "        return self.triplet(features, targets) + 0.0005 * self.center(features, targets)"
      ],
      "metadata": {
        "id": "v2m11AsaA0s1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Design of a customized learning rate scheduler with warm up"
      ],
      "metadata": {
        "id": "YsNeoqMxT9G9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bisect import bisect_right\n",
        "\n",
        "\n",
        "class WarmupMultiStepLR(torch.optim.lr_scheduler._LRScheduler):\n",
        "    def __init__(\n",
        "        self,\n",
        "        optimizer,\n",
        "        milestones,\n",
        "        gamma=0.1,\n",
        "        warmup_factor=1.0 / 3,\n",
        "        warmup_iters=500,\n",
        "        warmup_method=\"linear\",\n",
        "        last_epoch=-1,\n",
        "    ):\n",
        "        if not list(milestones) == sorted(milestones):\n",
        "            raise ValueError(\n",
        "                \"Milestones should be a list of\" \" increasing integers. Got {}\",\n",
        "                milestones,\n",
        "            )\n",
        "\n",
        "        if warmup_method not in (\"constant\", \"linear\"):\n",
        "            raise ValueError(\n",
        "                \"Only 'constant' or 'linear' warmup_method accepted\"\n",
        "                \"got {}\".format(warmup_method)\n",
        "            )\n",
        "        self.milestones = milestones\n",
        "        self.gamma = gamma\n",
        "        self.warmup_factor = warmup_factor\n",
        "        self.warmup_iters = warmup_iters\n",
        "        self.warmup_method = warmup_method\n",
        "        super(WarmupMultiStepLR, self).__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        warmup_factor = 1\n",
        "        if self.last_epoch < self.warmup_iters:\n",
        "            if self.warmup_method == \"constant\":\n",
        "                warmup_factor = self.warmup_factor\n",
        "            elif self.warmup_method == \"linear\":\n",
        "                alpha = self.last_epoch / self.warmup_iters\n",
        "                warmup_factor = self.warmup_factor * (1 - alpha) + alpha\n",
        "        return [\n",
        "            base_lr\n",
        "            * warmup_factor\n",
        "            * self.gamma ** bisect_right(self.milestones, self.last_epoch)\n",
        "            for base_lr in self.base_lrs\n",
        "        ]"
      ],
      "metadata": {
        "id": "xtIwUi09UCVC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_strategy(num_classes):\n",
        "    # The followings are used for training the embedding network\n",
        "    embedding = SEDense18(num_class=num_classes, is_reid=True).cuda()\n",
        "    # loss_function_embedding = contrastiveLoss(margin=300)\n",
        "    # loss_function_embedding = HybridLoss(margin=20)\n",
        "    loss_function_embedding = HybridLoss2(num_classes)\n",
        "    optimizer_embedding = torch.optim.Adam(embedding.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "    lr_scheduler_embedding = torch.optim.lr_scheduler.StepLR(optimizer_embedding, step_size=1000, gamma=0.5)\n",
        "    # lr_scheduler_embedding = WarmupMultiStepLR(optimizer_embedding, [5, 10], warmup_iters=10)\n",
        "    # lr_scheduler_embedding = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer_embedding, 10, eta_min=3.5e-5)\n",
        "    # The followings are used for training the classification network\n",
        "    classifier = embedding.classifier\n",
        "    loss_function_classifier = LabelSmoothing()\n",
        "    optimizer_classifier = torch.optim.Adam(classifier.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "    lr_scheduler_classifier = torch.optim.lr_scheduler.StepLR(optimizer_classifier, step_size=2000, gamma=0.5)\n",
        "    return embedding, loss_function_embedding, optimizer_embedding, lr_scheduler_embedding, \\\n",
        "        classifier, loss_function_classifier, optimizer_classifier, lr_scheduler_classifier\n"
      ],
      "metadata": {
        "id": "HvTLDxqL0xqP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import TensorDataset\n",
        "\n",
        "\n",
        "def train(image_path, pose_path, label_path, num_class, epochs=10, batch_size=64):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 64)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
        "        transforms.RandomErasing(),                           \n",
        "    ])\n",
        "    reid_dataset = CenTriDataset(image_path, label_path, transform)\n",
        "    losses_embed = list()\n",
        "    losses_class = list()\n",
        "    embed_model, loss_embed, optim_embed, lr_embed, class_model, loss_class, optim_class, lr_class = training_strategy(num_class)\n",
        "    embed_model.train()\n",
        "    for epoch in range(epochs):\n",
        "        # reid_dataset = MyDataset(image_path, pose_path, label_path, transform)\n",
        "        dataloader = DataLoaderX(reid_dataset, batch_size, True, num_workers=4, pin_memory=True)\n",
        "        iterator = tqdm(dataloader)\n",
        "        for sample in iterator:\n",
        "            optim_embed.zero_grad()\n",
        "            # image1, image2, pose1, pose2, labels, _ = sample\n",
        "            image, label = sample\n",
        "            image, label = image.cuda(), label.cuda()\n",
        "            # image1 = image1.cuda()\n",
        "            # image2 = image2.cuda()\n",
        "            # labels = labels.cuda()\n",
        "            # feature1 = embed_model(image1)\n",
        "            # feature2 = embed_model(image2)\n",
        "            feature = embed_model(image)\n",
        "            # loss = loss_embed(feature1, feature2, labels, pose1, pose2)\n",
        "            loss = loss_embed(feature, label)\n",
        "            # losses_embed.append(loss.item() / batch_size)\n",
        "            losses_embed.append(loss.item())\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(embed_model.parameters(), 10.)\n",
        "            optim_embed.step()\n",
        "            lr_embed.step()\n",
        "            status = \"epoch: {}, lr: {:.6f}, loss: {:.4f}\".format(epoch, lr_embed.get_last_lr()[0], loss.item())\n",
        "            iterator.set_description(status)\n",
        "    # Once the training is completed, do the inference to obtain the embeddings\n",
        "    embed_model = embed_model.eval()\n",
        "    feature_set = list()\n",
        "    label_set = list()\n",
        "    with torch.no_grad():\n",
        "        dataloader_inference = DataLoaderX(reid_dataset, batch_size, num_workers=4, pin_memory=True)\n",
        "        print(\"Start Inferencing..................\")\n",
        "        for sample in tqdm(dataloader_inference):\n",
        "            # image1, _, _, _, _, labels = sample\n",
        "            image1, labels = sample\n",
        "            image1 = image1.cuda()\n",
        "            feature1 = embed_model(image1)\n",
        "            feature_set.append(feature1.detach().cpu())\n",
        "            label_set.append(labels.detach().cpu())\n",
        "    feature_set = torch.cat(feature_set, dim=0)\n",
        "    label_set = torch.cat(label_set, dim=0)\n",
        "    classDataset = TensorDataset(feature_set, label_set)\n",
        "\n",
        "    class_model.train()\n",
        "    for epoch in range(epochs):\n",
        "        dataloader = DataLoaderX(classDataset, batch_size, True, num_workers=4, pin_memory=True)\n",
        "        iterator = tqdm(dataloader)\n",
        "        for sample in iterator:\n",
        "            optim_class.zero_grad()\n",
        "            embed, label = sample\n",
        "            embed = embed.cuda()\n",
        "            label = label.cuda()\n",
        "            prediction = class_model(embed)\n",
        "            loss = loss_class(prediction, label)\n",
        "            losses_class.append(loss.item())\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(class_model.parameters(), 10.)\n",
        "            optim_class.step()\n",
        "            lr_class.step()\n",
        "            status = \"epoch: {}, lr: {:.6f}, loss: {:.4f}\".format(epoch, lr_class.get_last_lr()[0], loss.item())\n",
        "            iterator.set_description(status)\n",
        "    class_model = class_model.eval()\n",
        "    return embed_model, class_model, losses_embed, losses_class\n",
        "\n",
        "\n",
        "def plot_losses(losses_embed, losses_class):\n",
        "    plt.figure()\n",
        "    plt.plot(losses_embed, linewidth=2, color=\"r\", label=\"embedding loss\")\n",
        "    plt.plot(losses_class, linewidth=2, color=\"b\", label=\"classifier loss\")\n",
        "    plt.xlabel(\"iterations\")\n",
        "    plt.ylabel(\"loss value\")\n",
        "    plt.title(\"loss functions\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "yWmKaFCGFDjd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = sorted(glob.glob(\"Market1501/bounding_box_train/*.jpg\"))\n",
        "pose_path = sorted(glob.glob(\"Market1501/bounding_box_train_pose/*.png\"))\n",
        "label_path = list(map(lambda x: int(x.split(\"/\")[-1][:4]), image_path))\n",
        "label_path = relabel(label_path)\n",
        "print(max(label_path))\n",
        "assert len(image_path) == len(pose_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Od8mXAKJt-M",
        "outputId": "17b270ce-611f-4d2c-c4d7-76abdc3ee97a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_model, class_model, losses_embed, losses_cls = train(image_path, pose_path, label_path, max(label_path)+1, 15)\n",
        "plot_losses(losses_embed, losses_cls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        },
        "id": "rljuxyPlO3Js",
        "outputId": "5ecb9532-8eab-4a9f-9c2a-6eeddbedb17e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "epoch: 0, lr: 0.001000, loss: 2.5512: 100%|██████████| 203/203 [00:53<00:00,  3.79it/s]\n",
            "epoch: 1, lr: 0.001000, loss: 2.6628: 100%|██████████| 203/203 [00:53<00:00,  3.79it/s]\n",
            "epoch: 2, lr: 0.001000, loss: 5.0208: 100%|██████████| 203/203 [00:53<00:00,  3.80it/s]\n",
            "epoch: 3, lr: 0.001000, loss: 2.3470: 100%|██████████| 203/203 [00:53<00:00,  3.81it/s]\n",
            "epoch: 4, lr: 0.000500, loss: 2.4065: 100%|██████████| 203/203 [00:53<00:00,  3.79it/s]\n",
            "epoch: 5, lr: 0.000500, loss: 2.1196: 100%|██████████| 203/203 [00:53<00:00,  3.82it/s]\n",
            "epoch: 6, lr: 0.000500, loss: 2.2539: 100%|██████████| 203/203 [00:53<00:00,  3.81it/s]\n",
            "epoch: 7, lr: 0.000500, loss: 1.8579: 100%|██████████| 203/203 [00:53<00:00,  3.80it/s]\n",
            "epoch: 8, lr: 0.000500, loss: 1.7932: 100%|██████████| 203/203 [00:53<00:00,  3.80it/s]\n",
            "epoch: 9, lr: 0.000250, loss: 1.8956: 100%|██████████| 203/203 [00:53<00:00,  3.82it/s]\n",
            "epoch: 10, lr: 0.000250, loss: 1.6360: 100%|██████████| 203/203 [00:53<00:00,  3.79it/s]\n",
            "epoch: 11, lr: 0.000250, loss: 1.6189: 100%|██████████| 203/203 [00:53<00:00,  3.80it/s]\n",
            "epoch: 12, lr: 0.000250, loss: 1.6433: 100%|██████████| 203/203 [00:53<00:00,  3.82it/s]\n",
            "epoch: 13, lr: 0.000250, loss: 1.8030: 100%|██████████| 203/203 [00:53<00:00,  3.80it/s]\n",
            "epoch: 14, lr: 0.000125, loss: 1.5852: 100%|██████████| 203/203 [00:53<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Inferencing..................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 203/203 [00:23<00:00,  8.47it/s]\n",
            "epoch: 0, lr: 0.005000, loss: 5.3505: 100%|██████████| 203/203 [00:02<00:00, 76.24it/s]\n",
            "epoch: 1, lr: 0.005000, loss: 5.1443: 100%|██████████| 203/203 [00:02<00:00, 78.13it/s]\n",
            "epoch: 2, lr: 0.005000, loss: 4.8176: 100%|██████████| 203/203 [00:02<00:00, 77.30it/s]\n",
            "epoch: 3, lr: 0.005000, loss: 4.3242: 100%|██████████| 203/203 [00:02<00:00, 78.58it/s]\n",
            "epoch: 4, lr: 0.005000, loss: 5.1127: 100%|██████████| 203/203 [00:02<00:00, 76.58it/s]\n",
            "epoch: 5, lr: 0.005000, loss: 3.8419: 100%|██████████| 203/203 [00:02<00:00, 78.27it/s]\n",
            "epoch: 6, lr: 0.005000, loss: 4.2143: 100%|██████████| 203/203 [00:02<00:00, 76.88it/s]\n",
            "epoch: 7, lr: 0.005000, loss: 3.5276: 100%|██████████| 203/203 [00:02<00:00, 77.89it/s]\n",
            "epoch: 8, lr: 0.005000, loss: 3.8461: 100%|██████████| 203/203 [00:03<00:00, 66.81it/s]\n",
            "epoch: 9, lr: 0.002500, loss: 2.6427: 100%|██████████| 203/203 [00:02<00:00, 77.02it/s]\n",
            "epoch: 10, lr: 0.002500, loss: 3.1354: 100%|██████████| 203/203 [00:02<00:00, 75.56it/s]\n",
            "epoch: 11, lr: 0.002500, loss: 4.3185: 100%|██████████| 203/203 [00:02<00:00, 77.17it/s]\n",
            "epoch: 12, lr: 0.002500, loss: 3.4264: 100%|██████████| 203/203 [00:03<00:00, 63.81it/s]\n",
            "epoch: 13, lr: 0.002500, loss: 3.4933: 100%|██████████| 203/203 [00:02<00:00, 75.21it/s]\n",
            "epoch: 14, lr: 0.002500, loss: 3.5309: 100%|██████████| 203/203 [00:02<00:00, 75.93it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do not train the network separately, merge the loss function together!"
      ],
      "metadata": {
        "id": "56YMDnvE6VRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SEDense18_split(nn.Module):\n",
        "    def __init__(self, num_class=751, needs_norm=True, is_reid=False):\n",
        "        super().__init__()\n",
        "        model = models.resnet18(pretrained=True)\n",
        "        self.conv0 = model.conv1\n",
        "        self.bn0 = model.bn1\n",
        "        self.relu0 = model.relu\n",
        "        self.pooling0 = model.maxpool\n",
        "        self.basicBlock11 = model.layer1[0]\n",
        "        self.seblock1 = SEBlock(64)\n",
        "\n",
        "        self.basicBlock12 = model.layer1[1]\n",
        "        self.seblock2 = SEBlock(64)\n",
        "\n",
        "        self.basicBlock21 = model.layer2[0]\n",
        "        self.seblock3 = SEBlock(128)\n",
        "        self.ancillaryconv3 = nn.Conv2d(64, 128, 1, 2, 0)\n",
        "        self.optionalNorm2dconv3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.basicBlock22 = model.layer2[1]\n",
        "        self.seblock4 = SEBlock(128)\n",
        "\n",
        "        self.basicBlock31 = model.layer3[0]\n",
        "        self.seblock5 = SEBlock(256)\n",
        "        self.ancillaryconv5 = nn.Conv2d(128, 256, 1, 2, 0)\n",
        "        self.optionalNorm2dconv5 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.basicBlock32 = model.layer3[1]\n",
        "        self.seblock6 = SEBlock(256)\n",
        "\n",
        "        self.basicBlock41 = model.layer4[0]\n",
        "        # last stride = 1\n",
        "        self.basicBlock41.conv1 = nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, device=\"cuda:0\")\n",
        "        self.basicBlock41.downsample[0] = nn.Conv2d(256, 512, kernel_size=(1,1), stride=(1,1), bias=False, device=\"cuda:0\")\n",
        "        self.seblock7 = SEBlock(512)\n",
        "        self.ancillaryconv7 = nn.Conv2d(256, 512, 1, 1, 0)\n",
        "        self.optionalNorm2dconv7 = nn.BatchNorm2d(512)\n",
        "\n",
        "        self.basicBlock42 = model.layer4[1]\n",
        "        self.seblock8 = SEBlock(512)\n",
        "\n",
        "        self.avgpooling = model.avgpool\n",
        "        self.bnneck = nn.BatchNorm1d(512)\n",
        "        self.bnneck.bias.requires_grad_(False)\n",
        "        # self.fc = nn.Linear(512, num_class)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256, num_class),\n",
        "        )\n",
        "        \n",
        "        self.needs_norm = needs_norm\n",
        "        self.is_reid = is_reid\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv0(x)\n",
        "        x = self.bn0(x)\n",
        "        x = self.relu0(x)\n",
        "        x = self.pooling0(x)\n",
        "        branch1 = x\n",
        "        x = self.basicBlock11(x)\n",
        "        scale1 = self.seblock1(x)\n",
        "        x = scale1 * x + branch1\n",
        "\n",
        "        branch2 = x\n",
        "        x = self.basicBlock12(x)\n",
        "        scale2 = self.seblock2(x)\n",
        "        x = scale2 * x + branch2\n",
        "\n",
        "        branch3 = x\n",
        "        x = self.basicBlock21(x)\n",
        "        scale3 = self.seblock3(x)\n",
        "        if self.needs_norm:\n",
        "            x = scale3 * x + self.optionalNorm2dconv3(self.ancillaryconv3(branch3))\n",
        "        else:\n",
        "            x = scale3 * x + self.ancillaryconv3(branch3)\n",
        "\n",
        "        branch4 = x\n",
        "        x = self.basicBlock22(x)\n",
        "        scale4 = self.seblock4(x)\n",
        "        x = scale4 * x + branch4\n",
        "\n",
        "        branch5 = x\n",
        "        x = self.basicBlock31(x)\n",
        "        scale5 = self.seblock5(x)\n",
        "        if self.needs_norm:\n",
        "            x = scale5 * x + self.optionalNorm2dconv5(self.ancillaryconv5(branch5))\n",
        "        else:\n",
        "            x = scale5 * x + self.ancillaryconv5(branch5)\n",
        "\n",
        "        branch6 = x\n",
        "        x = self.basicBlock32(x)\n",
        "        scale6 = self.seblock6(x)\n",
        "        x = scale6 * x + branch6\n",
        "\n",
        "        branch7 = x\n",
        "        x = self.basicBlock41(x)\n",
        "        scale7 = self.seblock7(x)\n",
        "        if self.needs_norm:\n",
        "            x = scale7 * x + self.optionalNorm2dconv7(self.ancillaryconv7(branch7))\n",
        "        else:\n",
        "            x = scale7 * x + self.ancillaryconv7(branch7)\n",
        "\n",
        "        branch8 = x\n",
        "        x = self.basicBlock42(x)\n",
        "        scale8 = self.seblock8(x)\n",
        "        x = scale8 * x + branch8\n",
        "\n",
        "        x = self.avgpooling(x)\n",
        "        feature = x.view(x.size(0), -1)\n",
        "        if self.is_reid:\n",
        "            return feature\n",
        "        x = self.bnneck(feature)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x, feature\n"
      ],
      "metadata": {
        "id": "JKwVhSJRA8wO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridLoss3(nn.Module):\n",
        "    def __init__(self, num_classes, feat_dim=512, margin=0.3, smoothing=0.1):\n",
        "        super().__init__()\n",
        "        self.center = CenterLoss(num_classes=num_classes, feat_dim=feat_dim)\n",
        "        self.triplet = TripletLoss(margin)\n",
        "        self.smooth = LabelSmoothing(smoothing)\n",
        "\n",
        "    def forward(self, embeddings, outputs, targets):\n",
        "        \"\"\"\n",
        "        features: feature vectors\n",
        "        targets: ground truth labels\n",
        "        \"\"\"\n",
        "        smooth_loss = self.smooth(outputs, targets)\n",
        "        triplet_loss = self.triplet(embeddings, targets)\n",
        "        center_loss = self.center(embeddings, targets)\n",
        "        return smooth_loss + triplet_loss + 0.0005 * center_loss"
      ],
      "metadata": {
        "id": "5dO6lRfp7fqS"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_strategy2(num_classes):\n",
        "    model = SEDense18_split(num_class=num_classes, is_reid=False).cuda()\n",
        "    loss_function = HybridLoss3(num_classes)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.5)\n",
        "    return model, loss_function, optimizer, lr_scheduler"
      ],
      "metadata": {
        "id": "cHkEfHqC6cDp"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train2(image_path, label_path, num_class, epochs=10, batch_size=64):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 64)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
        "        transforms.RandomErasing(),                           \n",
        "    ])\n",
        "    reid_dataset = CenTriDataset(image_path, label_path, transform)\n",
        "    losses_func = list()\n",
        "    model, loss_func, optim_func, lr_func = train_strategy2(num_class)\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        dataloader = DataLoaderX(reid_dataset, batch_size, True, num_workers=4, pin_memory=True)\n",
        "        iterator = tqdm(dataloader)\n",
        "        for sample in iterator:\n",
        "            optim_func.zero_grad()\n",
        "            image, label = sample\n",
        "            image, label = image.cuda(), label.cuda()\n",
        "\n",
        "            prediction, feature = model(image)\n",
        "\n",
        "            loss = loss_func(feature, prediction, label)\n",
        "\n",
        "            losses_func.append(loss.item())\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 10.)\n",
        "            optim_func.step()\n",
        "            lr_func.step()\n",
        "            status = \"epoch: {}, lr: {:.6f}, loss: {:.4f}\".format(epoch, lr_func.get_last_lr()[0], loss.item())\n",
        "            iterator.set_description(status)\n",
        "    model = model.eval()\n",
        "    return model, losses_func\n",
        "\n",
        "\n",
        "def plot_losses2(losses_func):\n",
        "    plt.figure()\n",
        "    plt.plot(losses_func, linewidth=2, color=\"r\", label=\"training loss\")\n",
        "    plt.xlabel(\"iterations\")\n",
        "    plt.ylabel(\"loss value\")\n",
        "    plt.title(\"loss functions\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "KQhCWaH5Azyx"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, losses_func = train2(image_path, label_path, max(label_path)+1, 25)\n",
        "plot_losses2(losses_func)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "id": "K5nPORbSCtsw",
        "outputId": "2b975d71-0e8a-45ef-ad6f-166f6f479529"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "epoch: 0, lr: 0.001000, loss: 6.5414: 100%|██████████| 203/203 [00:38<00:00,  5.24it/s]\n",
            "epoch: 1, lr: 0.001000, loss: 5.0197: 100%|██████████| 203/203 [00:38<00:00,  5.27it/s]\n",
            "epoch: 2, lr: 0.001000, loss: 4.7537: 100%|██████████| 203/203 [00:38<00:00,  5.23it/s]\n",
            "epoch: 3, lr: 0.001000, loss: 3.7465: 100%|██████████| 203/203 [00:38<00:00,  5.21it/s]\n",
            "epoch: 4, lr: 0.000500, loss: 3.1683: 100%|██████████| 203/203 [00:38<00:00,  5.30it/s]\n",
            "epoch: 5, lr: 0.000500, loss: 3.7832: 100%|██████████| 203/203 [00:38<00:00,  5.30it/s]\n",
            "epoch: 6, lr: 0.000500, loss: 3.8730: 100%|██████████| 203/203 [00:38<00:00,  5.31it/s]\n",
            "epoch: 7, lr: 0.000500, loss: 3.0330: 100%|██████████| 203/203 [00:38<00:00,  5.29it/s]\n",
            "epoch: 8, lr: 0.000500, loss: 2.9085: 100%|██████████| 203/203 [00:38<00:00,  5.24it/s]\n",
            "epoch: 9, lr: 0.000250, loss: 2.2786: 100%|██████████| 203/203 [00:38<00:00,  5.25it/s]\n",
            "epoch: 10, lr: 0.000250, loss: 2.8512: 100%|██████████| 203/203 [00:38<00:00,  5.31it/s]\n",
            "epoch: 11, lr: 0.000250, loss: 2.7448: 100%|██████████| 203/203 [00:38<00:00,  5.28it/s]\n",
            "epoch: 12, lr: 0.000250, loss: 3.6045: 100%|██████████| 203/203 [00:38<00:00,  5.29it/s]\n",
            "epoch: 13, lr: 0.000250, loss: 3.4106: 100%|██████████| 203/203 [00:38<00:00,  5.25it/s]\n",
            "epoch: 14, lr: 0.000125, loss: 2.8024: 100%|██████████| 203/203 [00:38<00:00,  5.27it/s]\n",
            "epoch: 15, lr: 0.000125, loss: 2.6560: 100%|██████████| 203/203 [00:38<00:00,  5.25it/s]\n",
            "epoch: 16, lr: 0.000125, loss: 2.4143: 100%|██████████| 203/203 [00:38<00:00,  5.28it/s]\n",
            "epoch: 17, lr: 0.000125, loss: 2.2271: 100%|██████████| 203/203 [00:37<00:00,  5.35it/s]\n",
            "epoch: 18, lr: 0.000125, loss: 2.9858: 100%|██████████| 203/203 [00:38<00:00,  5.34it/s]\n",
            "epoch: 19, lr: 0.000063, loss: 2.1966: 100%|██████████| 203/203 [00:38<00:00,  5.27it/s]\n",
            "epoch: 20, lr: 0.000063, loss: 2.7532: 100%|██████████| 203/203 [00:38<00:00,  5.26it/s]\n",
            "epoch: 21, lr: 0.000063, loss: 2.3539: 100%|██████████| 203/203 [00:38<00:00,  5.28it/s]\n",
            "epoch: 22, lr: 0.000063, loss: 3.2739: 100%|██████████| 203/203 [00:38<00:00,  5.33it/s]\n",
            "epoch: 23, lr: 0.000063, loss: 2.6045: 100%|██████████| 203/203 [00:38<00:00,  5.32it/s]\n",
            "epoch: 24, lr: 0.000031, loss: 2.9298: 100%|██████████| 203/203 [00:37<00:00,  5.35it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the model_split"
      ],
      "metadata": {
        "id": "8i82FGXgID0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "overall_model = SEDense18_split().cuda()\n",
        "overall_model.load_state_dict(model.state_dict())\n",
        "torch.save(overall_model.state_dict(), \"new_model_split_checkpoint.pt\")"
      ],
      "metadata": {
        "id": "Ip3JJkO-IAss"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall test on image labelling"
      ],
      "metadata": {
        "id": "nKXahSHinFPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "overall_model = SEDense18().cuda()\n",
        "overall_model.load_state_dict(embed_model.state_dict(), strict=False)\n",
        "for key in class_model.state_dict():\n",
        "    new_key = \"classifier.\" + key\n",
        "    class_model.state_dict()[new_key] = class_model.state_dict()[key].clone()\n",
        "overall_model.load_state_dict(class_model.state_dict(), strict=False)\n",
        "# traced_models = torch.jit.trace(overall_model, torch.randn((1,3,128,64)).to(\"cuda\"))\n",
        "# torch.jit.save(traced_models, \"new_model_checkpoint_traced.pt\")\n",
        "torch.save(overall_model.state_dict(), \"new_model_checkpoint.pt\")"
      ],
      "metadata": {
        "id": "rwgLBskPnCNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, image_path, label_path, transform):\n",
        "        super().__init__()\n",
        "        self.image_path = image_path\n",
        "        self.label_path = label_path\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_path)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image = self.image_path[idx]\n",
        "        label = self.label_path[idx]\n",
        "        image = Image.open(image).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(label).int()\n",
        "\n",
        "\n",
        "def test(image_path, label_path, batch_size=32):\n",
        "    overall_model = SEDense18(num_class=max(label_path)+1).cuda()\n",
        "    states = torch.load(\"new_model_checkpoint.pt\", map_location=lambda storage, loc: storage)\n",
        "    overall_model.load_state_dict(states)\n",
        "    overall_model.eval()\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 64)),  \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),                          \n",
        "    ])\n",
        "    test_dataset = TestDataset(image_path, label_path, transform)\n",
        "    dataloader = DataLoaderX(test_dataset, batch_size, num_workers=4, pin_memory=True)\n",
        "    acc = 0\n",
        "    with torch.no_grad():\n",
        "        iterator = tqdm(dataloader)\n",
        "        for sample in iterator:\n",
        "            image, label = sample\n",
        "            image, label = image.cuda(), label.cuda()\n",
        "            prediction = torch.argmax(overall_model(image), dim=1)\n",
        "            acc += torch.count_nonzero(torch.eq(prediction, label))\n",
        "    acc = acc / len(image_path)\n",
        "    return acc\n",
        "\n",
        "\n",
        "def test2(image_path, label_path, batch_size=32):\n",
        "    overall_model = SEDense18_split(num_class=max(label_path)+1).cuda()\n",
        "    states = torch.load(\"new_model_split_checkpoint.pt\", map_location=lambda storage, loc: storage)\n",
        "    overall_model.load_state_dict(states)\n",
        "    overall_model.eval()\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 64)),  \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),                          \n",
        "    ])\n",
        "    test_dataset = TestDataset(image_path, label_path, transform)\n",
        "    dataloader = DataLoaderX(test_dataset, batch_size, num_workers=4, pin_memory=True)\n",
        "    acc = 0\n",
        "    with torch.no_grad():\n",
        "        iterator = tqdm(dataloader)\n",
        "        for sample in iterator:\n",
        "            image, label = sample\n",
        "            image, label = image.cuda(), label.cuda()\n",
        "            prediction = torch.argmax(overall_model(image)[0], dim=1)\n",
        "            acc += torch.count_nonzero(torch.eq(prediction, label))\n",
        "    acc = acc / len(image_path)\n",
        "    return acc\n",
        "\n",
        "\n",
        "\n",
        "def test_dataset(path=\"Market1501/bounding_box_train\"):\n",
        "    image_path = sorted(glob.glob(path + \"/*.jpg\"))\n",
        "    label_path = list(map(lambda x: int(x.split(\"/\")[-1][:4]), image_path))\n",
        "    label_path = relabel(label_path)\n",
        "    return image_path, label_path\n",
        "\n"
      ],
      "metadata": {
        "id": "hejnFZzYrrLE"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path_test, label_path_test = test_dataset()\n",
        "# acc = test(image_path_test, label_path_test)\n",
        "acc = test2(image_path_test, label_path_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9TCnuOiYtSk",
        "outputId": "5158aa3c-b7e7-423e-e45c-6fe7f7aa29a2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 405/405 [00:23<00:00, 16.99it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PS5w2U0cmW3Y",
        "outputId": "62142acd-d1ea-4a74-8f62-bf32817df154"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9918058514595032"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the dissimilarity of the features. I want to know \n",
        "if my margin is convincing."
      ],
      "metadata": {
        "id": "HEZ8XWZLw9Gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dot_product(v1, v2):\n",
        "    return sum(map(lambda x: x[0] * x[1], zip(v1, v2)))\n",
        "\n",
        "def cosine_measure(v1, v2):\n",
        "    prod = dot_product(v1, v2)\n",
        "    len1 = math.sqrt(dot_product(v1, v1))\n",
        "    len2 = math.sqrt(dot_product(v2, v2))\n",
        "    return prod / (len1 * len2)\n",
        "\n",
        "\n",
        "def feature_acquisition(embed_model, image_path, label_path, batch_size=32):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 64)),  \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),                                      \n",
        "    ])\n",
        "    dataset = TestDataset(image_path, label_path, transform)\n",
        "    features = list()\n",
        "    labels = list()\n",
        "    torch.cuda.synchronize()\n",
        "    with torch.no_grad():\n",
        "        dataloader = DataLoaderX(dataset, batch_size, False, num_workers=4, pin_memory=True)\n",
        "        iterator = tqdm(dataloader)\n",
        "        for image, label in iterator:\n",
        "            image, label = image.cuda(), label.cuda()\n",
        "            feature = embed_model(image)\n",
        "            features.append(feature.detach().cpu().numpy())\n",
        "            labels.append(label.detach().cpu().numpy())\n",
        "        features = np.concatenate(features, axis=0)\n",
        "        labels = np.concatenate(labels, axis=0)\n",
        "    return features, labels\n",
        "\n",
        "\n",
        "def check_dissimilarity(features, labels):\n",
        "    max_dis_same = 0.\n",
        "    min_dis_diff = 1.\n",
        "    dissimilarity_score = defaultdict(list)\n",
        "    for idx, feature_x in enumerate(features):\n",
        "        for idy, feature_y in enumerate(features):\n",
        "            if idy <= idx:\n",
        "                continue\n",
        "            cosine_sim = cosine_measure(feature_x, feature_y)\n",
        "            if labels[idx] == labels[idy]:\n",
        "                dissimilarity_score[0].append(1 - cosine_sim)\n",
        "                max_dis_same = max(max_dis_same, cosine_sim)\n",
        "            else:\n",
        "                dissimilarity_score[1].append(1 - cosine_sim)\n",
        "                min_dis_diff = min(min_dis_diff, cosine_sim)\n",
        "    return dissimilarity_score, max_dis_same, min_dis_diff\n"
      ],
      "metadata": {
        "id": "900EOvjjw8rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path, label_path = test_dataset(\"Market1501/bounding_box_test\")"
      ],
      "metadata": {
        "id": "jPCDrH3n43Pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features, labels = feature_acquisition(embed_model, image_path, label_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u36rhRaoB26_",
        "outputId": "2e9c464c-eb39-48d2-bfc3-3685c06d1374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 410/410 [02:31<00:00,  2.70it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "DGpgIBuwNv6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = random.randint(0, len(image_path))\n",
        "idy = random.randint(0, len(image_path))\n",
        "# features_stacked = np.stack((features[idx], features[idy]))\n",
        "dis_sim = 1 - cosine_measure(features[idx], features[idy])\n",
        "# dis_sim = np.sum(np.abs(features[idx] - features[idy]) / features_stacked.std())\n",
        "print(image_path[idx], image_path[idy], dis_sim, labels[idx] == labels[idy])\n",
        "\n",
        "sameIdx, sameIdy = 1, 2\n",
        "dis_sim = 1 - cosine_measure(features[sameIdx], features[sameIdy])\n",
        "# features_stacked = np.stack((features[1], features[2]))\n",
        "# dis_sim = np.sum(np.abs(features[1] - features[2]) / features_stacked.std())\n",
        "print(image_path[sameIdx], image_path[sameIdy], dis_sim, labels[sameIdx] == labels[sameIdy])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6KNQIuFaUWX",
        "outputId": "417f5c6e-a437-4272-eb7c-b067035903c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Market1501/bounding_box_test/1170_c6s3_027467_01.jpg Market1501/bounding_box_test/0846_c3s2_107353_01.jpg 0.7972683483749926 False\n",
            "Market1501/bounding_box_test/0001_c1s1_002301_02.jpg Market1501/bounding_box_test/0001_c1s1_002401_02.jpg 0.12410911555463244 True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let me calculate the distance between different feature vectors\n",
        "idx = random.randint(0, len(image_path))\n",
        "idy = random.randint(0, len(image_path))\n",
        "dis1 = np.sqrt(np.sum((features[idx] - features[idy]) ** 2))\n",
        "dis2 = np.sqrt(np.sum((features[sameIdx] - features[sameIdy]) ** 2))\n",
        "print(\"Different labels\", dis1)\n",
        "print(\"Same labels\", dis2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdkJWqfmg5eN",
        "outputId": "98d1b72a-87c0-4886-ce79-bf3d4d69e7c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Different labels 81.54003\n",
            "Same labels 30.359818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(image_path[idx], image_path[idy])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsH0jITotcoe",
        "outputId": "87e9646a-2b8e-45ee-cc7c-7bdb8f529a6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Market1501/bounding_box_test/1059_c3s2_148819_06.jpg Market1501/bounding_box_test/0924_c3s2_115144_02.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This will take humongous time to run\n",
        "scores, max_dis_same, min_dis_diff = check_dissimilarity(features, labels)"
      ],
      "metadata": {
        "id": "qTefWuCFNrhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"max_dis_same is\", max_dis_same)\n",
        "print(\"min_dis_diff is\", min_dis_diff)"
      ],
      "metadata": {
        "id": "9UGjGoQh5VuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the loss function should consider the pose\n",
        "# Intuitively, we can set the loss function = 0.5 * contrastive loss + 0.5 * pose difference\n",
        "# check the pose difference in manhattan distance\n",
        "\n",
        "\n",
        "pose_image_path = sorted(glob.glob(\"Market1501/bounding_box_test_pose/*.jpg\"))\n",
        "pose_image_path = list(filter(lambda x: x.split(\"/\")[-1][0] != \"-\" and x.split(\"/\")[-1][:4] != \"0000\", pose_image_path))\n",
        "pose1 = transforms.ToTensor()(Image.open(pose_image_path[0]).convert(\"L\")).squeeze().numpy()\n",
        "pose2 = transforms.ToTensor()(Image.open(pose_image_path[1]).convert(\"L\")).squeeze().numpy()\n",
        "pose3 = transforms.ToTensor()(Image.open(pose_image_path[2]).convert(\"L\")).squeeze().numpy()\n",
        "print(\"Difference between {} and {} image pose is {}\".format(pose_image_path[0].split(\"/\")[-1], pose_image_path[1].split(\"/\")[-1], abs(pose1.sum() - pose2.sum())))\n",
        "print(\"Difference between {} and {} image pose is {}\".format(pose_image_path[1].split(\"/\")[-1], pose_image_path[2].split(\"/\")[-1], abs(pose2.sum() - pose3.sum())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbVcYksA-YFp",
        "outputId": "091fd6a3-20a2-49fa-9e00-c3c545760a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difference between 0001_c1s1_001051_03_rendered.jpg and 0001_c1s1_002301_02_rendered.jpg image pose is 41.8156852722168\n",
            "Difference between 0001_c1s1_002301_02_rendered.jpg and 0001_c1s1_002401_02_rendered.jpg image pose is 5.450984954833984\n"
          ]
        }
      ]
    }
  ]
}