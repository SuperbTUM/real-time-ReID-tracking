{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "REID_DEMO.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c107408a3b34e91a5eefd41783fb3f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_02e62507ec97426e9c7caeb965e1e7de",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ccf8c3139f0043218feaa14734faee42",
              "IPY_MODEL_76ea929985ee480098248e3c2c4bcb30",
              "IPY_MODEL_a240104d6be14c5ba9540679f028093b"
            ]
          }
        },
        "02e62507ec97426e9c7caeb965e1e7de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ccf8c3139f0043218feaa14734faee42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6ea67db098504795b3d01ee073b8661e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d7da961b1e945eeb2c8affdc0783e9a"
          }
        },
        "76ea929985ee480098248e3c2c4bcb30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f4c54688d6c34b8385dc0423d8f5902c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46830571,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46830571,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e235ac5473f4790942714c60466983d"
          }
        },
        "a240104d6be14c5ba9540679f028093b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_969ff13be03a437b8cef7338c348667d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 137MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eeac8359dab54bb0a8a2ac3394967685"
          }
        },
        "6ea67db098504795b3d01ee073b8661e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d7da961b1e945eeb2c8affdc0783e9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4c54688d6c34b8385dc0423d8f5902c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e235ac5473f4790942714c60466983d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "969ff13be03a437b8cef7338c348667d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eeac8359dab54bb0a8a2ac3394967685": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHPNQ0C7YNtv",
        "outputId": "b9944343-22a1-4dba-d08e-e7b59df56e13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Neural Network & Deep Learning\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "%cd /content/drive/My Drive/Neural Network & Deep Learning/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import glob\n",
        "import random\n",
        "from torchsummary import summary\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from prefetch_generator import BackgroundGenerator\n",
        "from torch.autograd import Variable\n",
        "import torch.backends.cudnn as cudnn\n",
        "from collections import defaultdict\n",
        "from math import sqrt\n",
        "from functools import reduce\n",
        "import numpy as np\n",
        "import math\n",
        "from PIL import Image\n",
        "cudnn.enabled = True\n",
        "cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "JBYyFpqWd1Gq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Have a look at the original resnet18 first"
      ],
      "metadata": {
        "id": "GZTRtz_Tfm-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "res18 = models.resnet18().cuda()\n",
        "res18.layer4[0].conv1 = nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, device=\"cuda:0\")\n",
        "res18.layer4[0].downsample[0] = nn.Conv2d(256, 512, kernel_size=(1,1), stride=(1,1), bias=False, device=\"cuda:0\")\n",
        "summary(res18, input_size=(3,128,64))\n",
        "# res18"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svgHjxJofqaJ",
        "outputId": "66fefff4-d4df-48a8-d16b-ade8dbee2061"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 64, 32]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 64, 32]             128\n",
            "              ReLU-3           [-1, 64, 64, 32]               0\n",
            "         MaxPool2d-4           [-1, 64, 32, 16]               0\n",
            "            Conv2d-5           [-1, 64, 32, 16]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 32, 16]             128\n",
            "              ReLU-7           [-1, 64, 32, 16]               0\n",
            "            Conv2d-8           [-1, 64, 32, 16]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 32, 16]             128\n",
            "             ReLU-10           [-1, 64, 32, 16]               0\n",
            "       BasicBlock-11           [-1, 64, 32, 16]               0\n",
            "           Conv2d-12           [-1, 64, 32, 16]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 32, 16]             128\n",
            "             ReLU-14           [-1, 64, 32, 16]               0\n",
            "           Conv2d-15           [-1, 64, 32, 16]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 32, 16]             128\n",
            "             ReLU-17           [-1, 64, 32, 16]               0\n",
            "       BasicBlock-18           [-1, 64, 32, 16]               0\n",
            "           Conv2d-19           [-1, 128, 16, 8]          73,728\n",
            "      BatchNorm2d-20           [-1, 128, 16, 8]             256\n",
            "             ReLU-21           [-1, 128, 16, 8]               0\n",
            "           Conv2d-22           [-1, 128, 16, 8]         147,456\n",
            "      BatchNorm2d-23           [-1, 128, 16, 8]             256\n",
            "           Conv2d-24           [-1, 128, 16, 8]           8,192\n",
            "      BatchNorm2d-25           [-1, 128, 16, 8]             256\n",
            "             ReLU-26           [-1, 128, 16, 8]               0\n",
            "       BasicBlock-27           [-1, 128, 16, 8]               0\n",
            "           Conv2d-28           [-1, 128, 16, 8]         147,456\n",
            "      BatchNorm2d-29           [-1, 128, 16, 8]             256\n",
            "             ReLU-30           [-1, 128, 16, 8]               0\n",
            "           Conv2d-31           [-1, 128, 16, 8]         147,456\n",
            "      BatchNorm2d-32           [-1, 128, 16, 8]             256\n",
            "             ReLU-33           [-1, 128, 16, 8]               0\n",
            "       BasicBlock-34           [-1, 128, 16, 8]               0\n",
            "           Conv2d-35            [-1, 256, 8, 4]         294,912\n",
            "      BatchNorm2d-36            [-1, 256, 8, 4]             512\n",
            "             ReLU-37            [-1, 256, 8, 4]               0\n",
            "           Conv2d-38            [-1, 256, 8, 4]         589,824\n",
            "      BatchNorm2d-39            [-1, 256, 8, 4]             512\n",
            "           Conv2d-40            [-1, 256, 8, 4]          32,768\n",
            "      BatchNorm2d-41            [-1, 256, 8, 4]             512\n",
            "             ReLU-42            [-1, 256, 8, 4]               0\n",
            "       BasicBlock-43            [-1, 256, 8, 4]               0\n",
            "           Conv2d-44            [-1, 256, 8, 4]         589,824\n",
            "      BatchNorm2d-45            [-1, 256, 8, 4]             512\n",
            "             ReLU-46            [-1, 256, 8, 4]               0\n",
            "           Conv2d-47            [-1, 256, 8, 4]         589,824\n",
            "      BatchNorm2d-48            [-1, 256, 8, 4]             512\n",
            "             ReLU-49            [-1, 256, 8, 4]               0\n",
            "       BasicBlock-50            [-1, 256, 8, 4]               0\n",
            "           Conv2d-51            [-1, 512, 8, 4]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 8, 4]           1,024\n",
            "             ReLU-53            [-1, 512, 8, 4]               0\n",
            "           Conv2d-54            [-1, 512, 8, 4]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 8, 4]           1,024\n",
            "           Conv2d-56            [-1, 512, 8, 4]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 8, 4]           1,024\n",
            "             ReLU-58            [-1, 512, 8, 4]               0\n",
            "       BasicBlock-59            [-1, 512, 8, 4]               0\n",
            "           Conv2d-60            [-1, 512, 8, 4]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 8, 4]           1,024\n",
            "             ReLU-62            [-1, 512, 8, 4]               0\n",
            "           Conv2d-63            [-1, 512, 8, 4]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 8, 4]           1,024\n",
            "             ReLU-65            [-1, 512, 8, 4]               0\n",
            "       BasicBlock-66            [-1, 512, 8, 4]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                 [-1, 1000]         513,000\n",
            "================================================================\n",
            "Total params: 11,689,512\n",
            "Trainable params: 11,689,512\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.09\n",
            "Forward/backward pass size (MB): 11.76\n",
            "Params size (MB): 44.59\n",
            "Estimated Total Size (MB): 56.45\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoaderX(DataLoader):\n",
        "    def __iter__(self):\n",
        "        return BackgroundGenerator(super().__iter__())"
      ],
      "metadata": {
        "id": "pdXgZkalEtYT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not know if the last layer for the embedding needs normalization"
      ],
      "metadata": {
        "id": "guS_8TkH5gdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, c_in):\n",
        "        super().__init__()\n",
        "        self.globalavgpooling = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc1 = nn.Linear(c_in, max(1, c_in // 16))\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.fc2 = nn.Linear(max(1, c_in // 16), c_in)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.c_in = c_in\n",
        "    \n",
        "    def forward(self, x):\n",
        "        assert self.c_in == x.size(1)\n",
        "        x = self.globalavgpooling(x)\n",
        "        x = x.squeeze()\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = x.unsqueeze(-1).unsqueeze(-1)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SEDense18(nn.Module):\n",
        "    def __init__(self, num_class=751, needs_norm=True, is_reid=False):\n",
        "        super().__init__()\n",
        "        model = models.resnet18(pretrained=True)\n",
        "        self.conv0 = model.conv1\n",
        "        self.bn0 = model.bn1\n",
        "        self.relu0 = model.relu\n",
        "        self.pooling0 = model.maxpool\n",
        "        self.basicBlock11 = model.layer1[0]\n",
        "        self.seblock1 = SEBlock(64)\n",
        "\n",
        "        self.basicBlock12 = model.layer1[1]\n",
        "        self.seblock2 = SEBlock(64)\n",
        "\n",
        "        self.basicBlock21 = model.layer2[0]\n",
        "        self.seblock3 = SEBlock(128)\n",
        "        self.ancillaryconv3 = nn.Conv2d(64, 128, 1, 2, 0)\n",
        "        self.optionalNorm2dconv3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.basicBlock22 = model.layer2[1]\n",
        "        self.seblock4 = SEBlock(128)\n",
        "\n",
        "        self.basicBlock31 = model.layer3[0]\n",
        "        self.seblock5 = SEBlock(256)\n",
        "        self.ancillaryconv5 = nn.Conv2d(128, 256, 1, 2, 0)\n",
        "        self.optionalNorm2dconv5 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.basicBlock32 = model.layer3[1]\n",
        "        self.seblock6 = SEBlock(256)\n",
        "\n",
        "        self.basicBlock41 = model.layer4[0]\n",
        "        # last stride = 1\n",
        "        self.basicBlock41.conv1 = nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, device=\"cuda:0\")\n",
        "        self.basicBlock41.downsample[0] = nn.Conv2d(256, 512, kernel_size=(1,1), stride=(1,1), bias=False, device=\"cuda:0\")\n",
        "        self.seblock7 = SEBlock(512)\n",
        "        self.ancillaryconv7 = nn.Conv2d(256, 512, 1, 1, 0)\n",
        "        self.optionalNorm2dconv7 = nn.BatchNorm2d(512)\n",
        "\n",
        "        self.basicBlock42 = model.layer4[1]\n",
        "        self.seblock8 = SEBlock(512)\n",
        "\n",
        "        self.avgpooling = model.avgpool\n",
        "        # self.fc = nn.Linear(512, num_class)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256, num_class),\n",
        "        )\n",
        "        self.needs_norm = needs_norm\n",
        "        self.is_reid = is_reid\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv0(x)\n",
        "        x = self.bn0(x)\n",
        "        x = self.relu0(x)\n",
        "        x = self.pooling0(x)\n",
        "        branch1 = x\n",
        "        x = self.basicBlock11(x)\n",
        "        scale1 = self.seblock1(x)\n",
        "        x = scale1 * x + branch1\n",
        "\n",
        "        branch2 = x\n",
        "        x = self.basicBlock12(x)\n",
        "        scale2 = self.seblock2(x)\n",
        "        x = scale2 * x + branch2\n",
        "\n",
        "        branch3 = x\n",
        "        x = self.basicBlock21(x)\n",
        "        scale3 = self.seblock3(x)\n",
        "        if self.needs_norm:\n",
        "            x = scale3 * x + self.optionalNorm2dconv3(self.ancillaryconv3(branch3))\n",
        "        else:\n",
        "            x = scale3 * x + self.ancillaryconv3(branch3)\n",
        "\n",
        "        branch4 = x\n",
        "        x = self.basicBlock22(x)\n",
        "        scale4 = self.seblock4(x)\n",
        "        x = scale4 * x + branch4\n",
        "\n",
        "        branch5 = x\n",
        "        x = self.basicBlock31(x)\n",
        "        scale5 = self.seblock5(x)\n",
        "        if self.needs_norm:\n",
        "            x = scale5 * x + self.optionalNorm2dconv5(self.ancillaryconv5(branch5))\n",
        "        else:\n",
        "            x = scale5 * x + self.ancillaryconv5(branch5)\n",
        "\n",
        "        branch6 = x\n",
        "        x = self.basicBlock32(x)\n",
        "        scale6 = self.seblock6(x)\n",
        "        x = scale6 * x + branch6\n",
        "\n",
        "        branch7 = x\n",
        "        x = self.basicBlock41(x)\n",
        "        scale7 = self.seblock7(x)\n",
        "        if self.needs_norm:\n",
        "            x = scale7 * x + self.optionalNorm2dconv7(self.ancillaryconv7(branch7))\n",
        "        else:\n",
        "            x = scale7 * x + self.ancillaryconv7(branch7)\n",
        "\n",
        "        branch8 = x\n",
        "        x = self.basicBlock42(x)\n",
        "        scale8 = self.seblock8(x)\n",
        "        x = scale8 * x + branch8\n",
        "\n",
        "        x = self.avgpooling(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        if self.is_reid:\n",
        "            return x\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "my_model = SEDense18().cuda()\n",
        "summary(my_model, input_size=(3, 128, 64))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6c107408a3b34e91a5eefd41783fb3f9",
            "02e62507ec97426e9c7caeb965e1e7de",
            "ccf8c3139f0043218feaa14734faee42",
            "76ea929985ee480098248e3c2c4bcb30",
            "a240104d6be14c5ba9540679f028093b",
            "6ea67db098504795b3d01ee073b8661e",
            "5d7da961b1e945eeb2c8affdc0783e9a",
            "f4c54688d6c34b8385dc0423d8f5902c",
            "8e235ac5473f4790942714c60466983d",
            "969ff13be03a437b8cef7338c348667d",
            "eeac8359dab54bb0a8a2ac3394967685"
          ]
        },
        "id": "wcgXv43eYkAu",
        "outputId": "f1647451-fc2d-455a-c84b-5c2b6836ef5c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c107408a3b34e91a5eefd41783fb3f9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 64, 32]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 64, 32]             128\n",
            "              ReLU-3           [-1, 64, 64, 32]               0\n",
            "         MaxPool2d-4           [-1, 64, 32, 16]               0\n",
            "            Conv2d-5           [-1, 64, 32, 16]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 32, 16]             128\n",
            "              ReLU-7           [-1, 64, 32, 16]               0\n",
            "            Conv2d-8           [-1, 64, 32, 16]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 32, 16]             128\n",
            "             ReLU-10           [-1, 64, 32, 16]               0\n",
            "       BasicBlock-11           [-1, 64, 32, 16]               0\n",
            "AdaptiveAvgPool2d-12             [-1, 64, 1, 1]               0\n",
            "           Linear-13                    [-1, 4]             260\n",
            "             ReLU-14                    [-1, 4]               0\n",
            "           Linear-15                   [-1, 64]             320\n",
            "          Sigmoid-16             [-1, 64, 1, 1]               0\n",
            "          SEBlock-17             [-1, 64, 1, 1]               0\n",
            "           Conv2d-18           [-1, 64, 32, 16]          36,864\n",
            "      BatchNorm2d-19           [-1, 64, 32, 16]             128\n",
            "             ReLU-20           [-1, 64, 32, 16]               0\n",
            "           Conv2d-21           [-1, 64, 32, 16]          36,864\n",
            "      BatchNorm2d-22           [-1, 64, 32, 16]             128\n",
            "             ReLU-23           [-1, 64, 32, 16]               0\n",
            "       BasicBlock-24           [-1, 64, 32, 16]               0\n",
            "AdaptiveAvgPool2d-25             [-1, 64, 1, 1]               0\n",
            "           Linear-26                    [-1, 4]             260\n",
            "             ReLU-27                    [-1, 4]               0\n",
            "           Linear-28                   [-1, 64]             320\n",
            "          Sigmoid-29             [-1, 64, 1, 1]               0\n",
            "          SEBlock-30             [-1, 64, 1, 1]               0\n",
            "           Conv2d-31           [-1, 128, 16, 8]          73,728\n",
            "      BatchNorm2d-32           [-1, 128, 16, 8]             256\n",
            "             ReLU-33           [-1, 128, 16, 8]               0\n",
            "           Conv2d-34           [-1, 128, 16, 8]         147,456\n",
            "      BatchNorm2d-35           [-1, 128, 16, 8]             256\n",
            "           Conv2d-36           [-1, 128, 16, 8]           8,192\n",
            "      BatchNorm2d-37           [-1, 128, 16, 8]             256\n",
            "             ReLU-38           [-1, 128, 16, 8]               0\n",
            "       BasicBlock-39           [-1, 128, 16, 8]               0\n",
            "AdaptiveAvgPool2d-40            [-1, 128, 1, 1]               0\n",
            "           Linear-41                    [-1, 8]           1,032\n",
            "             ReLU-42                    [-1, 8]               0\n",
            "           Linear-43                  [-1, 128]           1,152\n",
            "          Sigmoid-44            [-1, 128, 1, 1]               0\n",
            "          SEBlock-45            [-1, 128, 1, 1]               0\n",
            "           Conv2d-46           [-1, 128, 16, 8]           8,320\n",
            "      BatchNorm2d-47           [-1, 128, 16, 8]             256\n",
            "           Conv2d-48           [-1, 128, 16, 8]         147,456\n",
            "      BatchNorm2d-49           [-1, 128, 16, 8]             256\n",
            "             ReLU-50           [-1, 128, 16, 8]               0\n",
            "           Conv2d-51           [-1, 128, 16, 8]         147,456\n",
            "      BatchNorm2d-52           [-1, 128, 16, 8]             256\n",
            "             ReLU-53           [-1, 128, 16, 8]               0\n",
            "       BasicBlock-54           [-1, 128, 16, 8]               0\n",
            "AdaptiveAvgPool2d-55            [-1, 128, 1, 1]               0\n",
            "           Linear-56                    [-1, 8]           1,032\n",
            "             ReLU-57                    [-1, 8]               0\n",
            "           Linear-58                  [-1, 128]           1,152\n",
            "          Sigmoid-59            [-1, 128, 1, 1]               0\n",
            "          SEBlock-60            [-1, 128, 1, 1]               0\n",
            "           Conv2d-61            [-1, 256, 8, 4]         294,912\n",
            "      BatchNorm2d-62            [-1, 256, 8, 4]             512\n",
            "             ReLU-63            [-1, 256, 8, 4]               0\n",
            "           Conv2d-64            [-1, 256, 8, 4]         589,824\n",
            "      BatchNorm2d-65            [-1, 256, 8, 4]             512\n",
            "           Conv2d-66            [-1, 256, 8, 4]          32,768\n",
            "      BatchNorm2d-67            [-1, 256, 8, 4]             512\n",
            "             ReLU-68            [-1, 256, 8, 4]               0\n",
            "       BasicBlock-69            [-1, 256, 8, 4]               0\n",
            "AdaptiveAvgPool2d-70            [-1, 256, 1, 1]               0\n",
            "           Linear-71                   [-1, 16]           4,112\n",
            "             ReLU-72                   [-1, 16]               0\n",
            "           Linear-73                  [-1, 256]           4,352\n",
            "          Sigmoid-74            [-1, 256, 1, 1]               0\n",
            "          SEBlock-75            [-1, 256, 1, 1]               0\n",
            "           Conv2d-76            [-1, 256, 8, 4]          33,024\n",
            "      BatchNorm2d-77            [-1, 256, 8, 4]             512\n",
            "           Conv2d-78            [-1, 256, 8, 4]         589,824\n",
            "      BatchNorm2d-79            [-1, 256, 8, 4]             512\n",
            "             ReLU-80            [-1, 256, 8, 4]               0\n",
            "           Conv2d-81            [-1, 256, 8, 4]         589,824\n",
            "      BatchNorm2d-82            [-1, 256, 8, 4]             512\n",
            "             ReLU-83            [-1, 256, 8, 4]               0\n",
            "       BasicBlock-84            [-1, 256, 8, 4]               0\n",
            "AdaptiveAvgPool2d-85            [-1, 256, 1, 1]               0\n",
            "           Linear-86                   [-1, 16]           4,112\n",
            "             ReLU-87                   [-1, 16]               0\n",
            "           Linear-88                  [-1, 256]           4,352\n",
            "          Sigmoid-89            [-1, 256, 1, 1]               0\n",
            "          SEBlock-90            [-1, 256, 1, 1]               0\n",
            "           Conv2d-91            [-1, 512, 8, 4]       1,179,648\n",
            "      BatchNorm2d-92            [-1, 512, 8, 4]           1,024\n",
            "             ReLU-93            [-1, 512, 8, 4]               0\n",
            "           Conv2d-94            [-1, 512, 8, 4]       2,359,296\n",
            "      BatchNorm2d-95            [-1, 512, 8, 4]           1,024\n",
            "           Conv2d-96            [-1, 512, 8, 4]         131,072\n",
            "      BatchNorm2d-97            [-1, 512, 8, 4]           1,024\n",
            "             ReLU-98            [-1, 512, 8, 4]               0\n",
            "       BasicBlock-99            [-1, 512, 8, 4]               0\n",
            "AdaptiveAvgPool2d-100            [-1, 512, 1, 1]               0\n",
            "          Linear-101                   [-1, 32]          16,416\n",
            "            ReLU-102                   [-1, 32]               0\n",
            "          Linear-103                  [-1, 512]          16,896\n",
            "         Sigmoid-104            [-1, 512, 1, 1]               0\n",
            "         SEBlock-105            [-1, 512, 1, 1]               0\n",
            "          Conv2d-106            [-1, 512, 8, 4]         131,584\n",
            "     BatchNorm2d-107            [-1, 512, 8, 4]           1,024\n",
            "          Conv2d-108            [-1, 512, 8, 4]       2,359,296\n",
            "     BatchNorm2d-109            [-1, 512, 8, 4]           1,024\n",
            "            ReLU-110            [-1, 512, 8, 4]               0\n",
            "          Conv2d-111            [-1, 512, 8, 4]       2,359,296\n",
            "     BatchNorm2d-112            [-1, 512, 8, 4]           1,024\n",
            "            ReLU-113            [-1, 512, 8, 4]               0\n",
            "      BasicBlock-114            [-1, 512, 8, 4]               0\n",
            "AdaptiveAvgPool2d-115            [-1, 512, 1, 1]               0\n",
            "          Linear-116                   [-1, 32]          16,416\n",
            "            ReLU-117                   [-1, 32]               0\n",
            "          Linear-118                  [-1, 512]          16,896\n",
            "         Sigmoid-119            [-1, 512, 1, 1]               0\n",
            "         SEBlock-120            [-1, 512, 1, 1]               0\n",
            "AdaptiveAvgPool2d-121            [-1, 512, 1, 1]               0\n",
            "          Linear-122                  [-1, 256]         131,328\n",
            "     BatchNorm1d-123                  [-1, 256]             512\n",
            "            ReLU-124                  [-1, 256]               0\n",
            "         Dropout-125                  [-1, 256]               0\n",
            "          Linear-126                  [-1, 751]         193,007\n",
            "================================================================\n",
            "Total params: 11,765,159\n",
            "Trainable params: 11,765,159\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.09\n",
            "Forward/backward pass size (MB): 12.45\n",
            "Params size (MB): 44.88\n",
            "Estimated Total Size (MB): 57.43\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, image_path, pose_path, label_path, transform):\n",
        "        super().__init__()\n",
        "        self.image_path = image_path\n",
        "        self.pose_path = pose_path\n",
        "        self.label_path = label_path\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.image_path)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image1 = self.image_path[idx]\n",
        "        pose1 = self.pose_path[idx]\n",
        "        random_index = random.choice([i for i in range(len(self.image_path)) if i != idx])\n",
        "        image2 = self.image_path[random_index]\n",
        "        pose2 = self.pose_path[random_index]\n",
        "        relative_label = 0 if self.label_path[idx] == self.label_path[random_index] else 1\n",
        "        absolute_label = self.label_path[idx]\n",
        "        image1 = Image.open(image1).convert(\"RGB\")\n",
        "        image2 = Image.open(image2).convert(\"RGB\")\n",
        "        pose1 = transforms.ToTensor()(Image.open(pose1).convert(\"L\"))\n",
        "        pose2 = transforms.ToTensor()(Image.open(pose2).convert(\"L\"))\n",
        "        if self.transform:\n",
        "            image1 = self.transform(image1)\n",
        "            image2 = self.transform(image2)\n",
        "        relative_label = torch.tensor(relative_label).int()\n",
        "        absolute_label = torch.tensor(absolute_label).int()\n",
        "        return image1, image2, pose1, pose2, relative_label, absolute_label\n",
        "\n",
        "\n",
        "class CenTriDataset(Dataset):\n",
        "    def __init__(self, image_path, label_path, transform):\n",
        "        self.image_path = image_path\n",
        "        self.label_path = label_path\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.image_path)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image = self.image_path[idx]\n",
        "        label = self.label_path[idx]\n",
        "        image = Image.open(image).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(label).int()\n",
        "\n",
        "\n",
        "def relabel(label_set):\n",
        "    label = 0\n",
        "    latest_label = label_set[0]\n",
        "    new_label_set = list()\n",
        "    for cur_label in label_set:\n",
        "        if cur_label != latest_label:\n",
        "            label += 1\n",
        "            latest_label = cur_label\n",
        "        new_label_set.append(label)\n",
        "    return new_label_set"
      ],
      "metadata": {
        "id": "O8nJr2Q1dwhh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class contrastiveLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Contrastive loss function.\n",
        "    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, margin=20.0):\n",
        "        super(contrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
        "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
        "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "        return loss_contrastive\n",
        "\n",
        "\n",
        "class LabelSmoothing(nn.Module):\n",
        "    \"\"\" NLL loss with label smoothing. \"\"\"\n",
        "\n",
        "    def __init__(self, smoothing=0.1):\n",
        "        \"\"\" Constructor for the LabelSmoothing module.\n",
        "        :param smoothing: label smoothing factor \"\"\"\n",
        "        super(LabelSmoothing, self).__init__()\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "\n",
        "    def forward(self, x, target):\n",
        "        logprobs = torch.nn.functional.log_softmax(x, dim=-1)\n",
        "        target = target.long()\n",
        "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
        "        nll_loss = nll_loss.squeeze(1)\n",
        "        smooth_loss = -logprobs.mean(dim=-1)\n",
        "        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
        "        return loss.mean()\n",
        "\n"
      ],
      "metadata": {
        "id": "D4tuCWA77Kbb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding center loss and triplet to train the network based on strong baseline paper."
      ],
      "metadata": {
        "id": "i-KUr3ZoRG_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CenterLoss(nn.Module):\n",
        "    \"\"\"Center loss.\n",
        "    Reference:\n",
        "    Wen et al. A Discriminative Feature Learning Approach for Deep Face Recognition. ECCV 2016.\n",
        "    Args:\n",
        "        num_classes (int): number of classes.\n",
        "        feat_dim (int): feature dimension.\n",
        "    \"\"\"\n",
        " \n",
        "    def __init__(self, num_classes=751, feat_dim=2048, use_gpu=True):\n",
        "        super(CenterLoss, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.feat_dim = feat_dim\n",
        "        self.use_gpu = use_gpu\n",
        " \n",
        "        if self.use_gpu:\n",
        "            self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim).cuda())\n",
        "        else:\n",
        "            self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim))\n",
        " \n",
        "    def forward(self, x, labels):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: feature matrix with shape (batch_size, feat_dim).\n",
        "            labels: ground truth labels with shape (num_classes).\n",
        "        \"\"\"\n",
        "        assert x.size(0) == labels.size(0), \"features.size(0) is not equal to labels.size(0)\"\n",
        " \n",
        "        batch_size = x.size(0)\n",
        "        distmat = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(batch_size, self.num_classes) + \\\n",
        "                  torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.num_classes, batch_size).t()\n",
        "        distmat.addmm_(1, -2, x, self.centers.t())\n",
        " \n",
        "        classes = torch.arange(self.num_classes).long()\n",
        "        if self.use_gpu: classes = classes.cuda()\n",
        "        labels = labels.unsqueeze(1).expand(batch_size, self.num_classes)\n",
        "        mask = labels.eq(classes.expand(batch_size, self.num_classes))\n",
        " \n",
        "        dist = []\n",
        "        for i in range(batch_size):\n",
        "            value = distmat[i][mask[i]]\n",
        "            value = value.clamp(min=1e-12, max=1e+12)  # for numerical stability\n",
        "            dist.append(value)\n",
        "        dist = torch.cat(dist)\n",
        "        loss = dist.mean()\n",
        "        return loss\n",
        "\n",
        "\n",
        "class TripletLoss(nn.Module):\n",
        "    \"\"\"Triplet loss with hard positive/negative mining.\n",
        "    \n",
        "    Reference:\n",
        "        Hermans et al. In Defense of the Triplet Loss for Person Re-Identification. arXiv:1703.07737.\n",
        "    \n",
        "    Imported from `<https://github.com/Cysu/open-reid/blob/master/reid/loss/triplet.py>`_.\n",
        "    \n",
        "    Args:\n",
        "        margin (float, optional): margin for triplet. Default is 0.3.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, margin=0.3):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "        self.ranking_loss = nn.MarginRankingLoss(margin=margin)\n",
        " \n",
        "    def forward(self, inputs, targets):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            inputs (torch.Tensor): feature matrix with shape (batch_size, feat_dim).\n",
        "            targets (torch.LongTensor): ground truth labels with shape (num_classes).\n",
        "        \"\"\"\n",
        "        n = inputs.size(0)\n",
        "        \n",
        "        # Compute pairwise distance, replace by the official when merged\n",
        "        dist = torch.pow(inputs, 2).sum(dim=1, keepdim=True).expand(n, n)\n",
        "        dist = dist + dist.t()\n",
        "        dist.addmm_(1, -2, inputs, inputs.t())\n",
        "        dist = dist.clamp(min=1e-12).sqrt()  # for numerical stability\n",
        "        \n",
        "        # For each anchor, find the hardest positive and negative\n",
        "        mask = targets.expand(n, n).eq(targets.expand(n, n).t())\n",
        "        dist_ap, dist_an = [], []\n",
        "        for i in range(n):\n",
        "            dist_ap.append(dist[i][mask[i]].max().unsqueeze(0))\n",
        "            dist_an.append(dist[i][mask[i] == 0].min().unsqueeze(0))\n",
        "        dist_ap = torch.cat(dist_ap)\n",
        "        dist_an = torch.cat(dist_an)\n",
        "        \n",
        "        # Compute ranking hinge loss\n",
        "        y = torch.ones_like(dist_an)\n",
        "        return self.ranking_loss(dist_an, dist_ap, y)"
      ],
      "metadata": {
        "id": "QTxROLe7RGhJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I find it hard to do strict contrastive training since for the same person, there may be pose issues."
      ],
      "metadata": {
        "id": "LM58WQta-KaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PoseLoss(nn.Module):\n",
        "    def __init__(self, margin=None):\n",
        "        super().__init__()\n",
        "    \n",
        "    def forward(self, pose1, pose2):\n",
        "        return torch.log(torch.clamp(torch.abs(torch.sum(pose1) - torch.sum(pose2)), 0.) + 1e-6)\n",
        "\n",
        "class HybridLoss(nn.Module):\n",
        "    def __init__(self, margin=20.0):\n",
        "        super().__init__()\n",
        "        self.contrastive = contrastiveLoss(margin)\n",
        "        self.pose = PoseLoss()\n",
        "    \n",
        "    def forward(self, feature1, feature2, label, pose1, pose2):\n",
        "        return self.contrastive(feature1, feature2, label) + 0.05 * self.pose(pose1, pose2)\n",
        "\n",
        "\n",
        "class HybridLoss2(nn.Module):\n",
        "    def __init__(self, num_classes, feat_dim=512, margin=50):\n",
        "        super().__init__()\n",
        "        self.center = CenterLoss(num_classes=num_classes, feat_dim=feat_dim)\n",
        "        self.triplet = TripletLoss(margin)\n",
        "    \n",
        "    def forward(self, features, targets):\n",
        "        \"\"\"\n",
        "        features: feature vectors\n",
        "        targets: ground truth labels\n",
        "        \"\"\"\n",
        "        return self.triplet(features, targets) + 0.0005 * self.center(features, targets)"
      ],
      "metadata": {
        "id": "v2m11AsaA0s1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Design of a customized learning rate scheduler with warm up"
      ],
      "metadata": {
        "id": "YsNeoqMxT9G9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bisect import bisect_right\n",
        "\n",
        "\n",
        "class WarmupMultiStepLR(torch.optim.lr_scheduler._LRScheduler):\n",
        "    def __init__(\n",
        "        self,\n",
        "        optimizer,\n",
        "        milestones,\n",
        "        gamma=0.1,\n",
        "        warmup_factor=1.0 / 3,\n",
        "        warmup_iters=500,\n",
        "        warmup_method=\"linear\",\n",
        "        last_epoch=-1,\n",
        "    ):\n",
        "        if not list(milestones) == sorted(milestones):\n",
        "            raise ValueError(\n",
        "                \"Milestones should be a list of\" \" increasing integers. Got {}\",\n",
        "                milestones,\n",
        "            )\n",
        "\n",
        "        if warmup_method not in (\"constant\", \"linear\"):\n",
        "            raise ValueError(\n",
        "                \"Only 'constant' or 'linear' warmup_method accepted\"\n",
        "                \"got {}\".format(warmup_method)\n",
        "            )\n",
        "        self.milestones = milestones\n",
        "        self.gamma = gamma\n",
        "        self.warmup_factor = warmup_factor\n",
        "        self.warmup_iters = warmup_iters\n",
        "        self.warmup_method = warmup_method\n",
        "        super(WarmupMultiStepLR, self).__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        warmup_factor = 1\n",
        "        if self.last_epoch < self.warmup_iters:\n",
        "            if self.warmup_method == \"constant\":\n",
        "                warmup_factor = self.warmup_factor\n",
        "            elif self.warmup_method == \"linear\":\n",
        "                alpha = self.last_epoch / self.warmup_iters\n",
        "                warmup_factor = self.warmup_factor * (1 - alpha) + alpha\n",
        "        return [\n",
        "            base_lr\n",
        "            * warmup_factor\n",
        "            * self.gamma ** bisect_right(self.milestones, self.last_epoch)\n",
        "            for base_lr in self.base_lrs\n",
        "        ]"
      ],
      "metadata": {
        "id": "xtIwUi09UCVC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_strategy(num_classes):\n",
        "    # The followings are used for training the embedding network\n",
        "    embedding = SEDense18(num_class=num_classes, is_reid=True).cuda()\n",
        "    # loss_function_embedding = contrastiveLoss(margin=300)\n",
        "    # loss_function_embedding = HybridLoss(margin=20)\n",
        "    loss_function_embedding = HybridLoss2(num_classes)\n",
        "    optimizer_embedding = torch.optim.Adam(embedding.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "    lr_scheduler_embedding = torch.optim.lr_scheduler.StepLR(optimizer_embedding, step_size=1000, gamma=0.5)\n",
        "    # lr_scheduler_embedding = WarmupMultiStepLR(optimizer_embedding, [5, 10], warmup_iters=10)\n",
        "    # lr_scheduler_embedding = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer_embedding, 10, eta_min=3.5e-5)\n",
        "    # The followings are used for training the classification network\n",
        "    classifier = embedding.classifier\n",
        "    loss_function_classifier = LabelSmoothing()\n",
        "    optimizer_classifier = torch.optim.Adam(classifier.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "    lr_scheduler_classifier = torch.optim.lr_scheduler.StepLR(optimizer_classifier, step_size=2000, gamma=0.5)\n",
        "    return embedding, loss_function_embedding, optimizer_embedding, lr_scheduler_embedding, \\\n",
        "        classifier, loss_function_classifier, optimizer_classifier, lr_scheduler_classifier\n"
      ],
      "metadata": {
        "id": "HvTLDxqL0xqP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import TensorDataset\n",
        "\n",
        "\n",
        "def train(image_path, pose_path, label_path, num_class, epochs=10, batch_size=64):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 64)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
        "        transforms.RandomErasing(),                           \n",
        "    ])\n",
        "    reid_dataset = CenTriDataset(image_path, label_path, transform)\n",
        "    losses_embed = list()\n",
        "    losses_class = list()\n",
        "    embed_model, loss_embed, optim_embed, lr_embed, class_model, loss_class, optim_class, lr_class = training_strategy(num_class)\n",
        "    embed_model.train()\n",
        "    for epoch in range(epochs):\n",
        "        # reid_dataset = MyDataset(image_path, pose_path, label_path, transform)\n",
        "        dataloader = DataLoaderX(reid_dataset, batch_size, True, num_workers=4, pin_memory=True)\n",
        "        iterator = tqdm(dataloader)\n",
        "        for sample in iterator:\n",
        "            optim_embed.zero_grad()\n",
        "            # image1, image2, pose1, pose2, labels, _ = sample\n",
        "            image, label = sample\n",
        "            image, label = image.cuda(), label.cuda()\n",
        "            # image1 = image1.cuda()\n",
        "            # image2 = image2.cuda()\n",
        "            # labels = labels.cuda()\n",
        "            # feature1 = embed_model(image1)\n",
        "            # feature2 = embed_model(image2)\n",
        "            feature = embed_model(image)\n",
        "            # loss = loss_embed(feature1, feature2, labels, pose1, pose2)\n",
        "            loss = loss_embed(feature, label)\n",
        "            # losses_embed.append(loss.item() / batch_size)\n",
        "            losses_embed.append(loss.item())\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(embed_model.parameters(), 10.)\n",
        "            optim_embed.step()\n",
        "            lr_embed.step()\n",
        "            status = \"epoch: {}, lr: {:.6f}, loss: {:.4f}\".format(epoch, lr_embed.get_last_lr()[0], loss.item())\n",
        "            iterator.set_description(status)\n",
        "    # Once the training is completed, do the inference to obtain the embeddings\n",
        "    embed_model = embed_model.eval()\n",
        "    feature_set = list()\n",
        "    label_set = list()\n",
        "    with torch.no_grad():\n",
        "        dataloader_inference = DataLoaderX(reid_dataset, batch_size, num_workers=4, pin_memory=True)\n",
        "        print(\"Start Inferencing..................\")\n",
        "        for sample in tqdm(dataloader_inference):\n",
        "            # image1, _, _, _, _, labels = sample\n",
        "            image1, labels = sample\n",
        "            image1 = image1.cuda()\n",
        "            feature1 = embed_model(image1)\n",
        "            feature_set.append(feature1.detach().cpu())\n",
        "            label_set.append(labels.detach().cpu())\n",
        "    feature_set = torch.cat(feature_set, dim=0)\n",
        "    label_set = torch.cat(label_set, dim=0)\n",
        "    classDataset = TensorDataset(feature_set, label_set)\n",
        "\n",
        "    class_model.train()\n",
        "    for epoch in range(epochs):\n",
        "        dataloader = DataLoaderX(classDataset, batch_size, True, num_workers=4, pin_memory=True)\n",
        "        iterator = tqdm(dataloader)\n",
        "        for sample in iterator:\n",
        "            optim_class.zero_grad()\n",
        "            embed, label = sample\n",
        "            embed = embed.cuda()\n",
        "            label = label.cuda()\n",
        "            prediction = class_model(embed)\n",
        "            loss = loss_class(prediction, label)\n",
        "            losses_class.append(loss.item())\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(class_model.parameters(), 10.)\n",
        "            optim_class.step()\n",
        "            lr_class.step()\n",
        "            status = \"epoch: {}, lr: {:.6f}, loss: {:.4f}\".format(epoch, lr_class.get_last_lr()[0], loss.item())\n",
        "            iterator.set_description(status)\n",
        "    class_model = class_model.eval()\n",
        "    return embed_model, class_model, losses_embed, losses_class\n",
        "\n",
        "\n",
        "def plot_losses(losses_embed, losses_class):\n",
        "    plt.figure()\n",
        "    plt.plot(losses_embed, linewidth=2, color=\"r\", label=\"embedding loss\")\n",
        "    plt.plot(losses_class, linewidth=2, color=\"b\", label=\"classifier loss\")\n",
        "    plt.xlabel(\"iterations\")\n",
        "    plt.ylabel(\"loss value\")\n",
        "    plt.title(\"loss functions\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "yWmKaFCGFDjd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = sorted(glob.glob(\"Market1501/bounding_box_train/*.jpg\"))\n",
        "pose_path = sorted(glob.glob(\"Market1501/bounding_box_train_pose/*.png\"))\n",
        "label_path = list(map(lambda x: int(x.split(\"/\")[-1][:4]), image_path))\n",
        "label_path = relabel(label_path)\n",
        "print(max(label_path))\n",
        "assert len(image_path) == len(pose_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Od8mXAKJt-M",
        "outputId": "a49ada6b-32d0-4bfe-9365-93be73ca9aa1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_model, class_model, losses_embed, losses_cls = train(image_path, pose_path, label_path, max(label_path)+1, 15)\n",
        "plot_losses(losses_embed, losses_cls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        },
        "id": "rljuxyPlO3Js",
        "outputId": "5ecb9532-8eab-4a9f-9c2a-6eeddbedb17e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "epoch: 0, lr: 0.001000, loss: 2.5512: 100%|██████████| 203/203 [00:53<00:00,  3.79it/s]\n",
            "epoch: 1, lr: 0.001000, loss: 2.6628: 100%|██████████| 203/203 [00:53<00:00,  3.79it/s]\n",
            "epoch: 2, lr: 0.001000, loss: 5.0208: 100%|██████████| 203/203 [00:53<00:00,  3.80it/s]\n",
            "epoch: 3, lr: 0.001000, loss: 2.3470: 100%|██████████| 203/203 [00:53<00:00,  3.81it/s]\n",
            "epoch: 4, lr: 0.000500, loss: 2.4065: 100%|██████████| 203/203 [00:53<00:00,  3.79it/s]\n",
            "epoch: 5, lr: 0.000500, loss: 2.1196: 100%|██████████| 203/203 [00:53<00:00,  3.82it/s]\n",
            "epoch: 6, lr: 0.000500, loss: 2.2539: 100%|██████████| 203/203 [00:53<00:00,  3.81it/s]\n",
            "epoch: 7, lr: 0.000500, loss: 1.8579: 100%|██████████| 203/203 [00:53<00:00,  3.80it/s]\n",
            "epoch: 8, lr: 0.000500, loss: 1.7932: 100%|██████████| 203/203 [00:53<00:00,  3.80it/s]\n",
            "epoch: 9, lr: 0.000250, loss: 1.8956: 100%|██████████| 203/203 [00:53<00:00,  3.82it/s]\n",
            "epoch: 10, lr: 0.000250, loss: 1.6360: 100%|██████████| 203/203 [00:53<00:00,  3.79it/s]\n",
            "epoch: 11, lr: 0.000250, loss: 1.6189: 100%|██████████| 203/203 [00:53<00:00,  3.80it/s]\n",
            "epoch: 12, lr: 0.000250, loss: 1.6433: 100%|██████████| 203/203 [00:53<00:00,  3.82it/s]\n",
            "epoch: 13, lr: 0.000250, loss: 1.8030: 100%|██████████| 203/203 [00:53<00:00,  3.80it/s]\n",
            "epoch: 14, lr: 0.000125, loss: 1.5852: 100%|██████████| 203/203 [00:53<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Inferencing..................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 203/203 [00:23<00:00,  8.47it/s]\n",
            "epoch: 0, lr: 0.005000, loss: 5.3505: 100%|██████████| 203/203 [00:02<00:00, 76.24it/s]\n",
            "epoch: 1, lr: 0.005000, loss: 5.1443: 100%|██████████| 203/203 [00:02<00:00, 78.13it/s]\n",
            "epoch: 2, lr: 0.005000, loss: 4.8176: 100%|██████████| 203/203 [00:02<00:00, 77.30it/s]\n",
            "epoch: 3, lr: 0.005000, loss: 4.3242: 100%|██████████| 203/203 [00:02<00:00, 78.58it/s]\n",
            "epoch: 4, lr: 0.005000, loss: 5.1127: 100%|██████████| 203/203 [00:02<00:00, 76.58it/s]\n",
            "epoch: 5, lr: 0.005000, loss: 3.8419: 100%|██████████| 203/203 [00:02<00:00, 78.27it/s]\n",
            "epoch: 6, lr: 0.005000, loss: 4.2143: 100%|██████████| 203/203 [00:02<00:00, 76.88it/s]\n",
            "epoch: 7, lr: 0.005000, loss: 3.5276: 100%|██████████| 203/203 [00:02<00:00, 77.89it/s]\n",
            "epoch: 8, lr: 0.005000, loss: 3.8461: 100%|██████████| 203/203 [00:03<00:00, 66.81it/s]\n",
            "epoch: 9, lr: 0.002500, loss: 2.6427: 100%|██████████| 203/203 [00:02<00:00, 77.02it/s]\n",
            "epoch: 10, lr: 0.002500, loss: 3.1354: 100%|██████████| 203/203 [00:02<00:00, 75.56it/s]\n",
            "epoch: 11, lr: 0.002500, loss: 4.3185: 100%|██████████| 203/203 [00:02<00:00, 77.17it/s]\n",
            "epoch: 12, lr: 0.002500, loss: 3.4264: 100%|██████████| 203/203 [00:03<00:00, 63.81it/s]\n",
            "epoch: 13, lr: 0.002500, loss: 3.4933: 100%|██████████| 203/203 [00:02<00:00, 75.21it/s]\n",
            "epoch: 14, lr: 0.002500, loss: 3.5309: 100%|██████████| 203/203 [00:02<00:00, 75.93it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do not train the network separately, merge the loss function together!"
      ],
      "metadata": {
        "id": "56YMDnvE6VRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SEDense18_split(nn.Module):\n",
        "    def __init__(self, num_class=751, needs_norm=True, is_reid=False):\n",
        "        super().__init__()\n",
        "        model = models.resnet18(pretrained=True)\n",
        "        self.conv0 = model.conv1\n",
        "        self.bn0 = model.bn1\n",
        "        self.relu0 = model.relu\n",
        "        self.pooling0 = model.maxpool\n",
        "        self.basicBlock11 = model.layer1[0]\n",
        "        self.seblock1 = SEBlock(64)\n",
        "\n",
        "        self.basicBlock12 = model.layer1[1]\n",
        "        self.seblock2 = SEBlock(64)\n",
        "\n",
        "        self.basicBlock21 = model.layer2[0]\n",
        "        self.seblock3 = SEBlock(128)\n",
        "        self.ancillaryconv3 = nn.Conv2d(64, 128, 1, 2, 0)\n",
        "        self.optionalNorm2dconv3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.basicBlock22 = model.layer2[1]\n",
        "        self.seblock4 = SEBlock(128)\n",
        "\n",
        "        self.basicBlock31 = model.layer3[0]\n",
        "        self.seblock5 = SEBlock(256)\n",
        "        self.ancillaryconv5 = nn.Conv2d(128, 256, 1, 2, 0)\n",
        "        self.optionalNorm2dconv5 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.basicBlock32 = model.layer3[1]\n",
        "        self.seblock6 = SEBlock(256)\n",
        "\n",
        "        self.basicBlock41 = model.layer4[0]\n",
        "        # last stride = 1\n",
        "        self.basicBlock41.conv1 = nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, device=\"cuda:0\")\n",
        "        self.basicBlock41.downsample[0] = nn.Conv2d(256, 512, kernel_size=(1,1), stride=(1,1), bias=False, device=\"cuda:0\")\n",
        "        self.seblock7 = SEBlock(512)\n",
        "        self.ancillaryconv7 = nn.Conv2d(256, 512, 1, 1, 0)\n",
        "        self.optionalNorm2dconv7 = nn.BatchNorm2d(512)\n",
        "\n",
        "        self.basicBlock42 = model.layer4[1]\n",
        "        self.seblock8 = SEBlock(512)\n",
        "\n",
        "        self.avgpooling = model.avgpool\n",
        "        # self.fc = nn.Linear(512, num_class)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256, num_class),\n",
        "        )\n",
        "        self.needs_norm = needs_norm\n",
        "        self.is_reid = is_reid\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv0(x)\n",
        "        x = self.bn0(x)\n",
        "        x = self.relu0(x)\n",
        "        x = self.pooling0(x)\n",
        "        branch1 = x\n",
        "        x = self.basicBlock11(x)\n",
        "        scale1 = self.seblock1(x)\n",
        "        x = scale1 * x + branch1\n",
        "\n",
        "        branch2 = x\n",
        "        x = self.basicBlock12(x)\n",
        "        scale2 = self.seblock2(x)\n",
        "        x = scale2 * x + branch2\n",
        "\n",
        "        branch3 = x\n",
        "        x = self.basicBlock21(x)\n",
        "        scale3 = self.seblock3(x)\n",
        "        if self.needs_norm:\n",
        "            x = scale3 * x + self.optionalNorm2dconv3(self.ancillaryconv3(branch3))\n",
        "        else:\n",
        "            x = scale3 * x + self.ancillaryconv3(branch3)\n",
        "\n",
        "        branch4 = x\n",
        "        x = self.basicBlock22(x)\n",
        "        scale4 = self.seblock4(x)\n",
        "        x = scale4 * x + branch4\n",
        "\n",
        "        branch5 = x\n",
        "        x = self.basicBlock31(x)\n",
        "        scale5 = self.seblock5(x)\n",
        "        if self.needs_norm:\n",
        "            x = scale5 * x + self.optionalNorm2dconv5(self.ancillaryconv5(branch5))\n",
        "        else:\n",
        "            x = scale5 * x + self.ancillaryconv5(branch5)\n",
        "\n",
        "        branch6 = x\n",
        "        x = self.basicBlock32(x)\n",
        "        scale6 = self.seblock6(x)\n",
        "        x = scale6 * x + branch6\n",
        "\n",
        "        branch7 = x\n",
        "        x = self.basicBlock41(x)\n",
        "        scale7 = self.seblock7(x)\n",
        "        if self.needs_norm:\n",
        "            x = scale7 * x + self.optionalNorm2dconv7(self.ancillaryconv7(branch7))\n",
        "        else:\n",
        "            x = scale7 * x + self.ancillaryconv7(branch7)\n",
        "\n",
        "        branch8 = x\n",
        "        x = self.basicBlock42(x)\n",
        "        scale8 = self.seblock8(x)\n",
        "        x = scale8 * x + branch8\n",
        "\n",
        "        x = self.avgpooling(x)\n",
        "        feature = x.view(x.size(0), -1)\n",
        "        if self.is_reid:\n",
        "            return feature\n",
        "        x = self.classifier(feature)\n",
        "\n",
        "        return x, feature\n"
      ],
      "metadata": {
        "id": "JKwVhSJRA8wO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridLoss3(nn.Module):\n",
        "    def __init__(self, num_classes, feat_dim=512, margin=50, smoothing=0.1):\n",
        "        super().__init__()\n",
        "        self.center = CenterLoss(num_classes=num_classes, feat_dim=feat_dim)\n",
        "        self.triplet = TripletLoss(margin)\n",
        "        self.smooth = LabelSmoothing(smoothing)\n",
        "\n",
        "    def forward(self, embeddings, outputs, targets):\n",
        "        \"\"\"\n",
        "        features: feature vectors\n",
        "        targets: ground truth labels\n",
        "        \"\"\"\n",
        "        return self.smooth(outputs, targets) + self.triplet(embeddings, targets) + 0.0005 * self.center(embeddings, targets)"
      ],
      "metadata": {
        "id": "5dO6lRfp7fqS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_strategy2(num_classes):\n",
        "    model = SEDense18_split(num_class=num_classes, is_reid=False).cuda()\n",
        "    loss_function = HybridLoss3(num_classes)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.5)\n",
        "    return model, loss_function, optimizer, lr_scheduler"
      ],
      "metadata": {
        "id": "cHkEfHqC6cDp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train2(image_path, label_path, num_class, epochs=10, batch_size=64):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 64)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
        "        transforms.RandomErasing(),                           \n",
        "    ])\n",
        "    reid_dataset = CenTriDataset(image_path, label_path, transform)\n",
        "    losses_func = list()\n",
        "    model, loss_func, optim_func, lr_func = train_strategy2(num_class)\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        dataloader = DataLoaderX(reid_dataset, batch_size, True, num_workers=4, pin_memory=True)\n",
        "        iterator = tqdm(dataloader)\n",
        "        for sample in iterator:\n",
        "            optim_func.zero_grad()\n",
        "            image, label = sample\n",
        "            image, label = image.cuda(), label.cuda()\n",
        "\n",
        "            prediction, feature = model(image)\n",
        "\n",
        "            loss = loss_func(feature, prediction, label)\n",
        "\n",
        "            losses_func.append(loss.item())\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 10.)\n",
        "            optim_func.step()\n",
        "            lr_func.step()\n",
        "            status = \"epoch: {}, lr: {:.6f}, loss: {:.4f}\".format(epoch, lr_func.get_last_lr()[0], loss.item())\n",
        "            iterator.set_description(status)\n",
        "    model = model.eval()\n",
        "    return model, losses_func\n",
        "\n",
        "\n",
        "def plot_losses2(losses_func):\n",
        "    plt.figure()\n",
        "    plt.plot(losses_func, linewidth=2, color=\"r\", label=\"training loss\")\n",
        "    plt.xlabel(\"iterations\")\n",
        "    plt.ylabel(\"loss value\")\n",
        "    plt.title(\"loss functions\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "KQhCWaH5Azyx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, losses_func = train2(image_path, label_path, max(label_path)+1, 25)\n",
        "plot_losses2(losses_func)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "id": "K5nPORbSCtsw",
        "outputId": "e75151a3-c8f7-4ccb-f5f1-bdf33ab47938"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "epoch: 0, lr: 0.001000, loss: 8.3353: 100%|██████████| 203/203 [00:52<00:00,  3.87it/s]\n",
            "epoch: 1, lr: 0.001000, loss: 8.7185: 100%|██████████| 203/203 [00:52<00:00,  3.84it/s]\n",
            "epoch: 2, lr: 0.001000, loss: 7.9006: 100%|██████████| 203/203 [00:52<00:00,  3.86it/s]\n",
            "epoch: 3, lr: 0.001000, loss: 8.0598: 100%|██████████| 203/203 [00:53<00:00,  3.83it/s]\n",
            "epoch: 4, lr: 0.000500, loss: 7.2396: 100%|██████████| 203/203 [00:52<00:00,  3.84it/s]\n",
            "epoch: 5, lr: 0.000500, loss: 6.1003: 100%|██████████| 203/203 [00:52<00:00,  3.86it/s]\n",
            "epoch: 6, lr: 0.000500, loss: 6.3971: 100%|██████████| 203/203 [00:53<00:00,  3.83it/s]\n",
            "epoch: 7, lr: 0.000500, loss: 5.9327: 100%|██████████| 203/203 [00:52<00:00,  3.86it/s]\n",
            "epoch: 8, lr: 0.000500, loss: 5.7967: 100%|██████████| 203/203 [00:52<00:00,  3.86it/s]\n",
            "epoch: 9, lr: 0.000250, loss: 6.9536: 100%|██████████| 203/203 [00:52<00:00,  3.85it/s]\n",
            "epoch: 10, lr: 0.000250, loss: 6.3099: 100%|██████████| 203/203 [00:52<00:00,  3.85it/s]\n",
            "epoch: 11, lr: 0.000250, loss: 5.4852: 100%|██████████| 203/203 [00:52<00:00,  3.85it/s]\n",
            "epoch: 12, lr: 0.000250, loss: 5.3370: 100%|██████████| 203/203 [00:52<00:00,  3.83it/s]\n",
            "epoch: 13, lr: 0.000250, loss: 5.2211: 100%|██████████| 203/203 [00:53<00:00,  3.80it/s]\n",
            "epoch: 14, lr: 0.000125, loss: 6.1271: 100%|██████████| 203/203 [00:52<00:00,  3.86it/s]\n",
            "epoch: 15, lr: 0.000125, loss: 6.0889: 100%|██████████| 203/203 [00:52<00:00,  3.88it/s]\n",
            "epoch: 16, lr: 0.000125, loss: 4.8825: 100%|██████████| 203/203 [00:52<00:00,  3.86it/s]\n",
            "epoch: 17, lr: 0.000125, loss: 5.3482: 100%|██████████| 203/203 [00:52<00:00,  3.85it/s]\n",
            "epoch: 18, lr: 0.000125, loss: 5.1020: 100%|██████████| 203/203 [00:52<00:00,  3.85it/s]\n",
            "epoch: 19, lr: 0.000063, loss: 5.2424: 100%|██████████| 203/203 [00:52<00:00,  3.86it/s]\n",
            "epoch: 20, lr: 0.000063, loss: 4.3651: 100%|██████████| 203/203 [00:52<00:00,  3.86it/s]\n",
            "epoch: 21, lr: 0.000063, loss: 4.7858: 100%|██████████| 203/203 [00:52<00:00,  3.84it/s]\n",
            "epoch: 22, lr: 0.000063, loss: 5.8727: 100%|██████████| 203/203 [00:52<00:00,  3.88it/s]\n",
            "epoch: 23, lr: 0.000063, loss: 4.7580: 100%|██████████| 203/203 [00:52<00:00,  3.87it/s]\n",
            "epoch: 24, lr: 0.000031, loss: 4.9357: 100%|██████████| 203/203 [00:52<00:00,  3.88it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the model_split"
      ],
      "metadata": {
        "id": "8i82FGXgID0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "overall_model = SEDense18_split().cuda()\n",
        "overall_model.load_state_dict(model.state_dict())\n",
        "torch.save(overall_model.state_dict(), \"new_model_split_checkpoint.pt\")"
      ],
      "metadata": {
        "id": "Ip3JJkO-IAss"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall test on image labelling"
      ],
      "metadata": {
        "id": "nKXahSHinFPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "overall_model = SEDense18().cuda()\n",
        "overall_model.load_state_dict(embed_model.state_dict(), strict=False)\n",
        "for key in class_model.state_dict():\n",
        "    new_key = \"classifier.\" + key\n",
        "    class_model.state_dict()[new_key] = class_model.state_dict()[key].clone()\n",
        "overall_model.load_state_dict(class_model.state_dict(), strict=False)\n",
        "# traced_models = torch.jit.trace(overall_model, torch.randn((1,3,128,64)).to(\"cuda\"))\n",
        "# torch.jit.save(traced_models, \"new_model_checkpoint_traced.pt\")\n",
        "torch.save(overall_model.state_dict(), \"new_model_checkpoint.pt\")"
      ],
      "metadata": {
        "id": "rwgLBskPnCNU"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, image_path, label_path, transform):\n",
        "        super().__init__()\n",
        "        self.image_path = image_path\n",
        "        self.label_path = label_path\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_path)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image = self.image_path[idx]\n",
        "        label = self.label_path[idx]\n",
        "        image = Image.open(image).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(label).int()\n",
        "\n",
        "\n",
        "def test(image_path, label_path, batch_size=32):\n",
        "    overall_model = SEDense18(num_class=max(label_path)+1).cuda()\n",
        "    states = torch.load(\"new_model_checkpoint.pt\", map_location=lambda storage, loc: storage)\n",
        "    overall_model.load_state_dict(states)\n",
        "    overall_model.eval()\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 64)),  \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),                          \n",
        "    ])\n",
        "    test_dataset = TestDataset(image_path, label_path, transform)\n",
        "    dataloader = DataLoaderX(test_dataset, batch_size, num_workers=4, pin_memory=True)\n",
        "    acc = 0\n",
        "    with torch.no_grad():\n",
        "        iterator = tqdm(dataloader)\n",
        "        for sample in iterator:\n",
        "            image, label = sample\n",
        "            image, label = image.cuda(), label.cuda()\n",
        "            prediction = torch.argmax(overall_model(image), dim=1)\n",
        "            acc += torch.count_nonzero(torch.eq(prediction, label))\n",
        "    acc = acc / len(image_path)\n",
        "    return acc\n",
        "\n",
        "\n",
        "def test2(image_path, label_path, batch_size=32):\n",
        "    overall_model = SEDense18_split(num_class=max(label_path)+1).cuda()\n",
        "    states = torch.load(\"new_model_split_checkpoint.pt\", map_location=lambda storage, loc: storage)\n",
        "    overall_model.load_state_dict(states)\n",
        "    overall_model.eval()\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 64)),  \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),                          \n",
        "    ])\n",
        "    test_dataset = TestDataset(image_path, label_path, transform)\n",
        "    dataloader = DataLoaderX(test_dataset, batch_size, num_workers=4, pin_memory=True)\n",
        "    acc = 0\n",
        "    with torch.no_grad():\n",
        "        iterator = tqdm(dataloader)\n",
        "        for sample in iterator:\n",
        "            image, label = sample\n",
        "            image, label = image.cuda(), label.cuda()\n",
        "            prediction = torch.argmax(overall_model(image)[0], dim=1)\n",
        "            acc += torch.count_nonzero(torch.eq(prediction, label))\n",
        "    acc = acc / len(image_path)\n",
        "    return acc\n",
        "\n",
        "\n",
        "\n",
        "def test_dataset(path=\"Market1501/bounding_box_train\"):\n",
        "    image_path = sorted(glob.glob(path + \"/*.jpg\"))\n",
        "    label_path = list(map(lambda x: int(x.split(\"/\")[-1][:4]), image_path))\n",
        "    label_path = relabel(label_path)\n",
        "    return image_path, label_path\n",
        "\n"
      ],
      "metadata": {
        "id": "hejnFZzYrrLE"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path_test, label_path_test = test_dataset()\n",
        "# acc = test(image_path_test, label_path_test)\n",
        "acc = test2(image_path_test, label_path_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9TCnuOiYtSk",
        "outputId": "f06dfb92-5ba7-4632-a83c-6971db5b6e1f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 405/405 [00:32<00:00, 12.44it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PS5w2U0cmW3Y",
        "outputId": "cb91ab93-46be-46d9-e137-50bcbdaf4110"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7878015041351318"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the dissimilarity of the features. I want to know \n",
        "if my margin is convincing."
      ],
      "metadata": {
        "id": "HEZ8XWZLw9Gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dot_product(v1, v2):\n",
        "    return sum(map(lambda x: x[0] * x[1], zip(v1, v2)))\n",
        "\n",
        "def cosine_measure(v1, v2):\n",
        "    prod = dot_product(v1, v2)\n",
        "    len1 = math.sqrt(dot_product(v1, v1))\n",
        "    len2 = math.sqrt(dot_product(v2, v2))\n",
        "    return prod / (len1 * len2)\n",
        "\n",
        "\n",
        "def feature_acquisition(embed_model, image_path, label_path, batch_size=32):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 64)),  \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),                                      \n",
        "    ])\n",
        "    dataset = TestDataset(image_path, label_path, transform)\n",
        "    features = list()\n",
        "    labels = list()\n",
        "    torch.cuda.synchronize()\n",
        "    with torch.no_grad():\n",
        "        dataloader = DataLoaderX(dataset, batch_size, False, num_workers=4, pin_memory=True)\n",
        "        iterator = tqdm(dataloader)\n",
        "        for image, label in iterator:\n",
        "            image, label = image.cuda(), label.cuda()\n",
        "            feature = embed_model(image)\n",
        "            features.append(feature.detach().cpu().numpy())\n",
        "            labels.append(label.detach().cpu().numpy())\n",
        "        features = np.concatenate(features, axis=0)\n",
        "        labels = np.concatenate(labels, axis=0)\n",
        "    return features, labels\n",
        "\n",
        "\n",
        "def check_dissimilarity(features, labels):\n",
        "    max_dis_same = 0.\n",
        "    min_dis_diff = 1.\n",
        "    dissimilarity_score = defaultdict(list)\n",
        "    for idx, feature_x in enumerate(features):\n",
        "        for idy, feature_y in enumerate(features):\n",
        "            if idy <= idx:\n",
        "                continue\n",
        "            cosine_sim = cosine_measure(feature_x, feature_y)\n",
        "            if labels[idx] == labels[idy]:\n",
        "                dissimilarity_score[0].append(1 - cosine_sim)\n",
        "                max_dis_same = max(max_dis_same, cosine_sim)\n",
        "            else:\n",
        "                dissimilarity_score[1].append(1 - cosine_sim)\n",
        "                min_dis_diff = min(min_dis_diff, cosine_sim)\n",
        "    return dissimilarity_score, max_dis_same, min_dis_diff\n"
      ],
      "metadata": {
        "id": "900EOvjjw8rj"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path, label_path = test_dataset(\"Market1501/bounding_box_test\")"
      ],
      "metadata": {
        "id": "jPCDrH3n43Pz"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features, labels = feature_acquisition(embed_model, image_path, label_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u36rhRaoB26_",
        "outputId": "2e9c464c-eb39-48d2-bfc3-3685c06d1374"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 410/410 [02:31<00:00,  2.70it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "DGpgIBuwNv6j"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = random.randint(0, len(image_path))\n",
        "idy = random.randint(0, len(image_path))\n",
        "# features_stacked = np.stack((features[idx], features[idy]))\n",
        "dis_sim = 1 - cosine_measure(features[idx], features[idy])\n",
        "# dis_sim = np.sum(np.abs(features[idx] - features[idy]) / features_stacked.std())\n",
        "print(image_path[idx], image_path[idy], dis_sim, labels[idx] == labels[idy])\n",
        "\n",
        "sameIdx, sameIdy = 1, 2\n",
        "dis_sim = 1 - cosine_measure(features[sameIdx], features[sameIdy])\n",
        "# features_stacked = np.stack((features[1], features[2]))\n",
        "# dis_sim = np.sum(np.abs(features[1] - features[2]) / features_stacked.std())\n",
        "print(image_path[sameIdx], image_path[sameIdy], dis_sim, labels[sameIdx] == labels[sameIdy])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6KNQIuFaUWX",
        "outputId": "417f5c6e-a437-4272-eb7c-b067035903c1"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Market1501/bounding_box_test/1170_c6s3_027467_01.jpg Market1501/bounding_box_test/0846_c3s2_107353_01.jpg 0.7972683483749926 False\n",
            "Market1501/bounding_box_test/0001_c1s1_002301_02.jpg Market1501/bounding_box_test/0001_c1s1_002401_02.jpg 0.12410911555463244 True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let me calculate the distance between different feature vectors\n",
        "idx = random.randint(0, len(image_path))\n",
        "idy = random.randint(0, len(image_path))\n",
        "dis1 = np.sqrt(np.sum((features[idx] - features[idy]) ** 2))\n",
        "dis2 = np.sqrt(np.sum((features[sameIdx] - features[sameIdy]) ** 2))\n",
        "print(\"Different labels\", dis1)\n",
        "print(\"Same labels\", dis2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdkJWqfmg5eN",
        "outputId": "98d1b72a-87c0-4886-ce79-bf3d4d69e7c4"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Different labels 81.54003\n",
            "Same labels 30.359818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(image_path[idx], image_path[idy])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsH0jITotcoe",
        "outputId": "87e9646a-2b8e-45ee-cc7c-7bdb8f529a6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Market1501/bounding_box_test/1059_c3s2_148819_06.jpg Market1501/bounding_box_test/0924_c3s2_115144_02.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This will take humongous time to run\n",
        "scores, max_dis_same, min_dis_diff = check_dissimilarity(features, labels)"
      ],
      "metadata": {
        "id": "qTefWuCFNrhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"max_dis_same is\", max_dis_same)\n",
        "print(\"min_dis_diff is\", min_dis_diff)"
      ],
      "metadata": {
        "id": "9UGjGoQh5VuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the loss function should consider the pose\n",
        "# Intuitively, we can set the loss function = 0.5 * contrastive loss + 0.5 * pose difference\n",
        "# check the pose difference in manhattan distance\n",
        "\n",
        "\n",
        "pose_image_path = sorted(glob.glob(\"Market1501/bounding_box_test_pose/*.jpg\"))\n",
        "pose_image_path = list(filter(lambda x: x.split(\"/\")[-1][0] != \"-\" and x.split(\"/\")[-1][:4] != \"0000\", pose_image_path))\n",
        "pose1 = transforms.ToTensor()(Image.open(pose_image_path[0]).convert(\"L\")).squeeze().numpy()\n",
        "pose2 = transforms.ToTensor()(Image.open(pose_image_path[1]).convert(\"L\")).squeeze().numpy()\n",
        "pose3 = transforms.ToTensor()(Image.open(pose_image_path[2]).convert(\"L\")).squeeze().numpy()\n",
        "print(\"Difference between {} and {} image pose is {}\".format(pose_image_path[0].split(\"/\")[-1], pose_image_path[1].split(\"/\")[-1], abs(pose1.sum() - pose2.sum())))\n",
        "print(\"Difference between {} and {} image pose is {}\".format(pose_image_path[1].split(\"/\")[-1], pose_image_path[2].split(\"/\")[-1], abs(pose2.sum() - pose3.sum())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbVcYksA-YFp",
        "outputId": "091fd6a3-20a2-49fa-9e00-c3c545760a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difference between 0001_c1s1_001051_03_rendered.jpg and 0001_c1s1_002301_02_rendered.jpg image pose is 41.8156852722168\n",
            "Difference between 0001_c1s1_002301_02_rendered.jpg and 0001_c1s1_002401_02_rendered.jpg image pose is 5.450984954833984\n"
          ]
        }
      ]
    }
  ]
}