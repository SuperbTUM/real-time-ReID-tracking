{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "import random\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from prefetch_generator import BackgroundGenerator\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from collections import defaultdict\n",
    "from math import sqrt\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image\n",
    "from torchsummary import summary\n",
    "import time\n",
    "cudnn.enabled = True\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DataLoaderX(DataLoader):\n",
    "    def __iter__(self):\n",
    "        return BackgroundGenerator(super().__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, c_in):\n",
    "        super().__init__()\n",
    "        self.globalavgpooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(c_in, max(1, c_in // 16))\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Linear(max(1, c_in // 16), c_in)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.c_in = c_in\n",
    "    \n",
    "    def forward(self, x):\n",
    "        assert self.c_in == x.size(1)\n",
    "        x = self.globalavgpooling(x)\n",
    "        x = x.squeeze()\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x.unsqueeze(-1).unsqueeze(-1)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class IBN(nn.Module):\n",
    "    def __init__(self, in_channels, ratio=0.5):\n",
    "        \"\"\"\n",
    "        Some do instance norm, some do batch norm\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.ratio = ratio\n",
    "        self.half = int(self.in_channels * ratio)\n",
    "        self.IN = nn.InstanceNorm2d(self.half, affine=True)\n",
    "        self.BN = nn.BatchNorm2d(self.in_channels - self.half)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        split = torch.split(x, self.half, 1)\n",
    "        out1 = self.IN(split[0].contiguous())\n",
    "        out2 = self.BN(split[1].contiguous())\n",
    "        out = torch.cat((out1, out2), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM,self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "        \n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n",
    "\n",
    "\n",
    "class SEDense18_IBN(nn.Module):\n",
    "    def __init__(self, num_class=751, needs_norm=True, is_reid=False):\n",
    "        super().__init__()\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        self.conv0 = model.conv1\n",
    "        self.bn0 = model.bn1\n",
    "        self.relu0 = model.relu\n",
    "        self.pooling0 = model.maxpool\n",
    "\n",
    "        model.layer1[0].bn1 = IBN(64)\n",
    "        self.basicBlock11 = model.layer1[0]\n",
    "        self.seblock1 = SEBlock(64)\n",
    "\n",
    "        self.basicBlock12 = model.layer1[1]\n",
    "        self.seblock2 = SEBlock(64)\n",
    "\n",
    "        model.layer2[0].bn1 = IBN(128)\n",
    "        self.basicBlock21 = model.layer2[0]\n",
    "        self.seblock3 = SEBlock(128)\n",
    "        self.ancillaryconv3 = nn.Conv2d(64, 128, 1, 2, 0)\n",
    "        self.optionalNorm2dconv3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.basicBlock22 = model.layer2[1]\n",
    "        self.seblock4 = SEBlock(128)\n",
    "        \n",
    "        model.layer3[0].bn1 = IBN(256)\n",
    "        self.basicBlock31 = model.layer3[0]\n",
    "        self.seblock5 = SEBlock(256)\n",
    "        self.ancillaryconv5 = nn.Conv2d(128, 256, 1, 2, 0)\n",
    "        self.optionalNorm2dconv5 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.basicBlock32 = model.layer3[1]\n",
    "        self.seblock6 = SEBlock(256)\n",
    "\n",
    "        self.basicBlock41 = model.layer4[0]\n",
    "        # last stride = 1\n",
    "        self.basicBlock41.conv1 = nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, device=\"cuda:0\")\n",
    "        self.basicBlock41.downsample[0] = nn.Conv2d(256, 512, kernel_size=(1,1), stride=(1,1), bias=False, device=\"cuda:0\")\n",
    "        self.seblock7 = SEBlock(512)\n",
    "        self.ancillaryconv7 = nn.Conv2d(256, 512, 1, 1, 0)\n",
    "        self.optionalNorm2dconv7 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.basicBlock42 = model.layer4[1]\n",
    "        self.seblock8 = SEBlock(512)\n",
    "\n",
    "        self.avgpooling = model.avgpool\n",
    "        # self.avgpooling = GeM()\n",
    "\n",
    "        self.bnneck = nn.BatchNorm1d(512)\n",
    "        self.bnneck.bias.requires_grad_(False)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, num_class),\n",
    "        )\n",
    "        self.needs_norm = needs_norm\n",
    "        self.is_reid = is_reid\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        x = self.bn0(x)\n",
    "        x = self.relu0(x)\n",
    "        x = self.pooling0(x)\n",
    "        branch1 = x\n",
    "        x = self.basicBlock11(x)\n",
    "        scale1 = self.seblock1(x)\n",
    "        x = scale1 * x + branch1\n",
    "\n",
    "        branch2 = x\n",
    "        x = self.basicBlock12(x)\n",
    "        scale2 = self.seblock2(x)\n",
    "        x = scale2 * x + branch2\n",
    "\n",
    "        branch3 = x\n",
    "        x = self.basicBlock21(x)\n",
    "        scale3 = self.seblock3(x)\n",
    "        if self.needs_norm:\n",
    "            x = scale3 * x + self.optionalNorm2dconv3(self.ancillaryconv3(branch3))\n",
    "        else:\n",
    "            x = scale3 * x + self.ancillaryconv3(branch3)\n",
    "\n",
    "        branch4 = x\n",
    "        x = self.basicBlock22(x)\n",
    "        scale4 = self.seblock4(x)\n",
    "        x = scale4 * x + branch4\n",
    "\n",
    "        branch5 = x\n",
    "        x = self.basicBlock31(x)\n",
    "        scale5 = self.seblock5(x)\n",
    "        if self.needs_norm:\n",
    "            x = scale5 * x + self.optionalNorm2dconv5(self.ancillaryconv5(branch5))\n",
    "        else:\n",
    "            x = scale5 * x + self.ancillaryconv5(branch5)\n",
    "\n",
    "        branch6 = x\n",
    "        x = self.basicBlock32(x)\n",
    "        scale6 = self.seblock6(x)\n",
    "        x = scale6 * x + branch6\n",
    "\n",
    "        branch7 = x\n",
    "        x = self.basicBlock41(x)\n",
    "        scale7 = self.seblock7(x)\n",
    "        if self.needs_norm:\n",
    "            x = scale7 * x + self.optionalNorm2dconv7(self.ancillaryconv7(branch7))\n",
    "        else:\n",
    "            x = scale7 * x + self.ancillaryconv7(branch7)\n",
    "\n",
    "        branch8 = x\n",
    "        x = self.basicBlock42(x)\n",
    "        scale8 = self.seblock8(x)\n",
    "        x = scale8 * x + branch8\n",
    "\n",
    "        x = self.avgpooling(x)\n",
    "        feature = x.view(x.size(0), -1)\n",
    "        if self.is_reid:\n",
    "            return feature\n",
    "        x = self.bnneck(feature)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def relabel(label_set):\n",
    "    label = 0\n",
    "    latest_label = label_set[0]\n",
    "    new_label_set = list()\n",
    "    for cur_label in label_set:\n",
    "        if cur_label != latest_label:\n",
    "            label += 1\n",
    "            latest_label = cur_label\n",
    "        new_label_set.append(label)\n",
    "    return new_label_set\n",
    "\n",
    "\n",
    "image_path = sorted(glob.glob(\"../../Market-1501/bounding_box_train/*.jpg\"))\n",
    "label_path = list(map(lambda x: int(x.split(\"/\")[-1][:4]), image_path))\n",
    "label_path = relabel(label_path)\n",
    "assert max(label_path) == 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11265\n"
     ]
    }
   ],
   "source": [
    "def check_distribution(label_path):\n",
    "    unique, counts = np.unique(np.asarray(label_path), return_counts=True)\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.bar(unique, counts, width=1)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    return np.median(counts)\n",
    "\n",
    "# I am not sure how to set the baseline. Let's try 15 as it is the median\n",
    "def augmentation(images, transform, num):\n",
    "    augments = list()\n",
    "    for _ in range(num):\n",
    "        reference = np.random.choice(len(images))\n",
    "        augments.append(transform(images[reference]))\n",
    "    images.extend(augments)\n",
    "    return images\n",
    "\n",
    "def reorganize(image_path, label_path, base=15):\n",
    "    d = defaultdict(list)\n",
    "    for i, image in enumerate(image_path):\n",
    "        image_ = Image.open(image).convert(\"RGB\")\n",
    "        image_ = transforms.ToTensor()(image_)\n",
    "        d[label_path[i]].append(image_)\n",
    "    for key in d:\n",
    "        if len(d[key]) >= base:\n",
    "            # sample\n",
    "            indices = np.random.choice(len(d[key]), size=base, replace=False)\n",
    "            original = d[key][:]\n",
    "            d[key].clear()\n",
    "            for indice in indices:\n",
    "                d[key].append(original[indice])\n",
    "        else:\n",
    "            # augment\n",
    "            transform = transforms.Compose([\n",
    "                transforms.RandomErasing(),\n",
    "                transforms.RandomHorizontalFlip(),                           \n",
    "            ])\n",
    "            d[key] = augmentation(d[key], transform, base-len(d[key]))\n",
    "    balanced_label_path = []\n",
    "    for i in range(len(d)):\n",
    "        balanced_label_path.extend([i for _ in range(base)])\n",
    "    balanced_image_path = []\n",
    "    for label in range(len(d)):\n",
    "        balanced_image_path.extend(d[label])\n",
    "    return balanced_image_path, balanced_label_path # tensors, list[int]\n",
    "\n",
    "base = check_distribution(label_path)\n",
    "balanced_image_path, balanced_label_path = reorganize(image_path, label_path, int(base))\n",
    "print(len(balanced_image_path)) # much larger than the previous dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BalancedDataset(Dataset):\n",
    "    def __init__(self, image_path, label_path, transform):\n",
    "        super().__init__()\n",
    "        self.image_path = image_path\n",
    "        self.label_path = label_path\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_path)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.image_path[idx]\n",
    "        label = self.label_path[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(label).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    \"\"\" NLL loss with label smoothing. \"\"\"\n",
    "\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        \"\"\" Constructor for the LabelSmoothing module.\n",
    "        :param smoothing: label smoothing factor \"\"\"\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        logprobs = torch.nn.functional.log_softmax(x, dim=-1)\n",
    "        target = target.long()\n",
    "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "        nll_loss = nll_loss.squeeze(1)\n",
    "        smooth_loss = -logprobs.mean(dim=-1)\n",
    "        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CenterLoss(nn.Module):\n",
    "    \"\"\"Center loss.\n",
    "    Reference:\n",
    "    Wen et al. A Discriminative Feature Learning Approach for Deep Face Recognition. ECCV 2016.\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        feat_dim (int): feature dimension.\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self, num_classes=751, feat_dim=2048, use_gpu=True):\n",
    "        super(CenterLoss, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.feat_dim = feat_dim\n",
    "        self.use_gpu = use_gpu\n",
    " \n",
    "        if self.use_gpu:\n",
    "            self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim).cuda())\n",
    "        else:\n",
    "            self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim))\n",
    " \n",
    "    def forward(self, x, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: feature matrix with shape (batch_size, feat_dim).\n",
    "            labels: ground truth labels with shape (num_classes).\n",
    "        \"\"\"\n",
    "        assert x.size(0) == labels.size(0), \"features.size(0) is not equal to labels.size(0)\"\n",
    " \n",
    "        batch_size = x.size(0)\n",
    "        distmat = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(batch_size, self.num_classes) + \\\n",
    "                  torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.num_classes, batch_size).t()\n",
    "        distmat.addmm_(1, -2, x, self.centers.t())\n",
    " \n",
    "        classes = torch.arange(self.num_classes).long()\n",
    "        if self.use_gpu: classes = classes.cuda()\n",
    "        labels = labels.unsqueeze(1).expand(batch_size, self.num_classes)\n",
    "        mask = labels.eq(classes.expand(batch_size, self.num_classes))\n",
    " \n",
    "        dist = []\n",
    "        for i in range(batch_size):\n",
    "            value = distmat[i][mask[i]]\n",
    "            value = value.clamp(min=1e-12, max=1e+12)  # for numerical stability\n",
    "            dist.append(value)\n",
    "        dist = torch.cat(dist)\n",
    "        loss = dist.mean()\n",
    "        return loss\n",
    "\n",
    "\n",
    "class TripletLoss(nn.Module):\n",
    "    \"\"\"Triplet loss with hard positive/negative mining.\n",
    "    \n",
    "    Reference:\n",
    "        Hermans et al. In Defense of the Triplet Loss for Person Re-Identification. arXiv:1703.07737.\n",
    "    \n",
    "    Imported from `<https://github.com/Cysu/open-reid/blob/master/reid/loss/triplet.py>`_.\n",
    "    \n",
    "    Args:\n",
    "        margin (float, optional): margin for triplet. Default is 0.3.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, margin=0.3):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.ranking_loss = nn.MarginRankingLoss(margin=margin)\n",
    " \n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs (torch.Tensor): feature matrix with shape (batch_size, feat_dim).\n",
    "            targets (torch.LongTensor): ground truth labels with shape (num_classes).\n",
    "        \"\"\"\n",
    "        n = inputs.size(0)\n",
    "        \n",
    "        # Compute pairwise distance, replace by the official when merged\n",
    "        dist = torch.pow(inputs, 2).sum(dim=1, keepdim=True).expand(n, n)\n",
    "        dist = dist + dist.t()\n",
    "        dist.addmm_(1, -2, inputs, inputs.t())\n",
    "        dist = dist.clamp(min=1e-12).sqrt()  # for numerical stability\n",
    "        \n",
    "        # For each anchor, find the hardest positive and negative\n",
    "        mask = targets.expand(n, n).eq(targets.expand(n, n).t())\n",
    "        dist_ap, dist_an = [], []\n",
    "        for i in range(n):\n",
    "            dist_ap.append(dist[i][mask[i]].max().unsqueeze(0))\n",
    "            dist_an.append(dist[i][mask[i] == 0].min().unsqueeze(0))\n",
    "        dist_ap = torch.cat(dist_ap)\n",
    "        dist_an = torch.cat(dist_an)\n",
    "        \n",
    "        # Compute ranking hinge loss\n",
    "        y = torch.ones_like(dist_an)\n",
    "        return self.ranking_loss(dist_an, dist_ap, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class HybridLoss3(nn.Module):\n",
    "    def __init__(self, num_classes, feat_dim=512, margin=0.3, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.center = CenterLoss(num_classes=num_classes, feat_dim=feat_dim)\n",
    "        self.triplet = TripletLoss(margin)\n",
    "        self.smooth = LabelSmoothing(smoothing)\n",
    "\n",
    "    def forward(self, embeddings, outputs, targets):\n",
    "        \"\"\"\n",
    "        features: feature vectors\n",
    "        targets: ground truth labels\n",
    "        \"\"\"\n",
    "        smooth_loss = self.smooth(outputs, targets)\n",
    "        triplet_loss = self.triplet(embeddings, targets)\n",
    "        center_loss = self.center(embeddings, targets)\n",
    "        return smooth_loss + triplet_loss + 0.0005 * center_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from bisect import bisect_right\n",
    "\n",
    "\n",
    "class WarmupMultiStepLR(torch.optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(\n",
    "        self,\n",
    "        optimizer,\n",
    "        milestones,\n",
    "        gamma=0.1,\n",
    "        warmup_factor=1.0 / 3,\n",
    "        warmup_iters=300,\n",
    "        warmup_method=\"linear\",\n",
    "        last_epoch=-1,\n",
    "    ):\n",
    "        if not list(milestones) == sorted(milestones):\n",
    "            raise ValueError(\n",
    "                \"Milestones should be a list of\" \" increasing integers. Got {}\",\n",
    "                milestones,\n",
    "            )\n",
    "\n",
    "        if warmup_method not in (\"constant\", \"linear\"):\n",
    "            raise ValueError(\n",
    "                \"Only 'constant' or 'linear' warmup_method accepted\"\n",
    "                \"got {}\".format(warmup_method)\n",
    "            )\n",
    "        self.milestones = milestones\n",
    "        self.gamma = gamma\n",
    "        self.warmup_factor = warmup_factor\n",
    "        self.warmup_iters = warmup_iters\n",
    "        self.warmup_method = warmup_method\n",
    "        super(WarmupMultiStepLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        warmup_factor = 1\n",
    "        if self.last_epoch < self.warmup_iters:\n",
    "            if self.warmup_method == \"constant\":\n",
    "                warmup_factor = self.warmup_factor\n",
    "            elif self.warmup_method == \"linear\":\n",
    "                alpha = self.last_epoch / self.warmup_iters\n",
    "                warmup_factor = self.warmup_factor * (1 - alpha) + alpha\n",
    "        return [\n",
    "            base_lr\n",
    "            * warmup_factor\n",
    "            * self.gamma ** bisect_right(self.milestones, self.last_epoch)\n",
    "            for base_lr in self.base_lrs\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_strategy2(num_classes):\n",
    "    model = SEDense18_IBN(num_class=num_classes, is_reid=False).cuda()\n",
    "    loss_function = HybridLoss3(num_classes)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 150)\n",
    "    return model, loss_function, optimizer, lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train3(image_path, label_path, num_class, epochs=10, batch_size=64):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 64)),\n",
    "        transforms.Pad(10),\n",
    "        transforms.RandomCrop((128, 64)), \n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    reid_dataset = BalancedDataset(image_path, label_path, transform)\n",
    "    losses_func = list()\n",
    "    model, loss_func, optim_func, lr_func = train_strategy2(num_class)\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        dataloader = DataLoaderX(reid_dataset, batch_size, True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "        iterator = tqdm(dataloader)\n",
    "        for sample in iterator:\n",
    "            optim_func.zero_grad()\n",
    "            image, label = sample\n",
    "            image, label = image.cuda(), label.cuda()\n",
    "            \n",
    "            prediction, feature = model(image)\n",
    "\n",
    "            loss = loss_func(feature, prediction, label)\n",
    "\n",
    "            losses_func.append(loss.item())\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 10.)\n",
    "            optim_func.step()\n",
    "            lr_func.step()\n",
    "            status = \"epoch: {}, lr: {:.6f}, loss: {:.4f}\".format(epoch, lr_func.get_last_lr()[0], loss.item())\n",
    "            iterator.set_description(status)\n",
    "    model = model.eval()\n",
    "    return model, losses_func\n",
    "\n",
    "\n",
    "def plot_losses3(losses_func):\n",
    "    plt.figure()\n",
    "    plt.plot(losses_func, linewidth=2, color=\"r\", label=\"training loss\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"loss value\")\n",
    "    plt.title(\"loss functions\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/176 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:77: UserWarning: This overload of addmm_ is deprecated:\n",
      "\taddmm_(Number beta, Number alpha, Tensor mat1, Tensor mat2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddmm_(Tensor mat1, Tensor mat2, *, Number beta, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)\n",
      "epoch: 0, lr: 0.000928, loss: 6.3801: 100%|██████████| 176/176 [00:23<00:00,  7.65it/s]\n",
      "epoch: 1, lr: 0.000732, loss: 5.7394: 100%|██████████| 176/176 [00:21<00:00,  8.33it/s]\n",
      "epoch: 2, lr: 0.000469, loss: 5.2701: 100%|██████████| 176/176 [00:21<00:00,  8.09it/s]\n",
      "epoch: 3, lr: 0.000215, loss: 4.6954: 100%|██████████| 176/176 [00:21<00:00,  8.16it/s]\n",
      "epoch: 4, lr: 0.000043, loss: 4.2559: 100%|██████████| 176/176 [00:21<00:00,  8.29it/s]\n",
      "epoch: 5, lr: 0.000996, loss: 3.8812: 100%|██████████| 176/176 [00:22<00:00,  7.83it/s]\n",
      "epoch: 6, lr: 0.000892, loss: 3.7624: 100%|██████████| 176/176 [00:21<00:00,  8.37it/s]\n",
      "epoch: 7, lr: 0.000674, loss: 3.2019: 100%|██████████| 176/176 [00:21<00:00,  8.34it/s]\n",
      "epoch: 8, lr: 0.000406, loss: 3.2560: 100%|██████████| 176/176 [00:22<00:00,  7.93it/s]\n",
      "epoch: 9, lr: 0.000165, loss: 2.9350: 100%|██████████| 176/176 [00:21<00:00,  8.37it/s]\n",
      "epoch: 10, lr: 0.000021, loss: 2.7299: 100%|██████████| 176/176 [00:21<00:00,  8.37it/s]\n",
      "epoch: 11, lr: 0.000984, loss: 2.8005: 100%|██████████| 176/176 [00:22<00:00,  7.84it/s]\n",
      "epoch: 12, lr: 0.000850, loss: 2.6752: 100%|██████████| 176/176 [00:20<00:00,  8.41it/s]\n",
      "epoch: 13, lr: 0.000614, loss: 2.6009: 100%|██████████| 176/176 [00:21<00:00,  8.35it/s]\n",
      "epoch: 14, lr: 0.000345, loss: 2.4793: 100%|██████████| 176/176 [00:22<00:00,  7.84it/s]\n",
      "epoch: 15, lr: 0.000122, loss: 2.1632: 100%|██████████| 176/176 [00:21<00:00,  8.37it/s]\n",
      "epoch: 16, lr: 0.000007, loss: 2.3139: 100%|██████████| 176/176 [00:22<00:00,  7.90it/s]\n",
      "epoch: 17, lr: 0.000965, loss: 2.4853: 100%|██████████| 176/176 [00:21<00:00,  8.37it/s]\n",
      "epoch: 18, lr: 0.000802, loss: 2.4133: 100%|██████████| 176/176 [00:21<00:00,  8.36it/s]\n",
      "epoch: 19, lr: 0.000552, loss: 2.2732: 100%|██████████| 176/176 [00:22<00:00,  7.89it/s]\n",
      "epoch: 20, lr: 0.000287, loss: 2.0721: 100%|██████████| 176/176 [00:21<00:00,  8.36it/s]\n",
      "epoch: 21, lr: 0.000084, loss: 2.2091: 100%|██████████| 176/176 [00:20<00:00,  8.48it/s]\n",
      "epoch: 22, lr: 0.000000, loss: 1.9767: 100%|██████████| 176/176 [00:22<00:00,  7.89it/s]\n",
      "epoch: 23, lr: 0.000938, loss: 2.1892: 100%|██████████| 176/176 [00:20<00:00,  8.39it/s]\n",
      "epoch: 24, lr: 0.000750, loss: 2.1874: 100%|██████████| 176/176 [00:20<00:00,  8.41it/s]\n",
      "epoch: 25, lr: 0.000490, loss: 2.0152: 100%|██████████| 176/176 [00:22<00:00,  7.93it/s]\n",
      "epoch: 26, lr: 0.000232, loss: 1.9602: 100%|██████████| 176/176 [00:20<00:00,  8.41it/s]\n",
      "epoch: 27, lr: 0.000052, loss: 1.8682: 100%|██████████| 176/176 [00:20<00:00,  8.44it/s]\n",
      "epoch: 28, lr: 0.000998, loss: 1.9058: 100%|██████████| 176/176 [00:22<00:00,  7.92it/s]\n",
      "epoch: 29, lr: 0.000905, loss: 2.0071: 100%|██████████| 176/176 [00:20<00:00,  8.38it/s]\n",
      "epoch: 30, lr: 0.000694, loss: 1.9243: 100%|██████████| 176/176 [00:22<00:00,  7.88it/s]\n",
      "epoch: 31, lr: 0.000427, loss: 1.9606: 100%|██████████| 176/176 [00:20<00:00,  8.44it/s]\n",
      "epoch: 32, lr: 0.000181, loss: 1.8078: 100%|██████████| 176/176 [00:20<00:00,  8.42it/s]\n",
      "epoch: 33, lr: 0.000028, loss: 1.7807: 100%|██████████| 176/176 [00:22<00:00,  7.93it/s]\n",
      "epoch: 34, lr: 0.000989, loss: 1.8500: 100%|██████████| 176/176 [00:21<00:00,  8.36it/s]\n",
      "epoch: 35, lr: 0.000864, loss: 2.0574: 100%|██████████| 176/176 [00:20<00:00,  8.49it/s]\n",
      "epoch: 36, lr: 0.000634, loss: 1.8673: 100%|██████████| 176/176 [00:22<00:00,  7.96it/s]\n",
      "epoch: 37, lr: 0.000366, loss: 1.9476: 100%|██████████| 176/176 [00:21<00:00,  8.37it/s]\n",
      "epoch: 38, lr: 0.000136, loss: 1.7575: 100%|██████████| 176/176 [00:20<00:00,  8.42it/s]\n",
      "epoch: 39, lr: 0.000011, loss: 1.8209: 100%|██████████| 176/176 [00:22<00:00,  7.93it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAyq0lEQVR4nO3dd5hU1fnA8e9LkQVBQMAVRQG7grRFpFhYRCl2TRR7x/hLNCZCotFYozEmttixJxpRQbEBIrooioKAgDTFgoKKINKWopT398e547Q7s7O7c6e+n+e5z9w5t5x3l+WdO+eee46oKsYYYwpPnWwHYIwxJhiW4I0xpkBZgjfGmAJlCd4YYwqUJXhjjClQluCNMaZAWYI3OUFEFotI/wzV1VBEXhGRNSLyfCbqjKh7noj0zWSdpnjVy3YAxmTBr4BSoIWqbgmqEhF5AliqqteEylS1Q1D1GRPLruBNMWoLfBpkcjcmF1iCNzlHRBqIyF0i8q233CUiDbxtLUXkVRFZLSI/ishkEanjbfuziHwjIutE5BMROcLn3DcA1wKnikiliFwgIteLyFMR+7QTERWRet77SSJyk4i85517goi0jNj/EBGZ4sW0RETOFZGhwBnAn7x6XvH2/aUpqoqfs6+ILBWRK0RkuYh8JyLnRdQ5WETme/F8IyLD0v8vYfKdJXiTi64GegJdgM5ADyDUzHEFsBRohWtm+QugIrIv8DvgIFVtAgwAFseeWFWvA24BnlXVxqr6aIoxnQ6cB+wEbAcMAxCR3YFxwD1eTF2AWao6AngauM2r59hq/pwAOwNNgV2BC4D7RKS5t+1R4GLvZ+0IvJXiz2GKiCV4k4vOAG5U1eWqugK4ATjL27YZaA20VdXNqjpZ3YBKW4EGwAEiUl9VF6vq52mM6XFV/VRVNwLP4ZJyKNaJqvqMF89KVZ2V4jmT/ZzgftYbvfOOBSqBfSO2HSAiO6jqKlWdWbsfzxQiS/AmF+0CfBXx/iuvDOCfwGfABBH5QkSuBFDVz4DLgeuB5SIyUkR2IX2WRaxvABp767sBNf0gSfZzAqyMuU8QWe/JwGDgKxF5W0R61TAGU8AswZtc9C3uRmjI7l4ZqrpOVa9Q1T2AY4E/htraVfV/qnqId6wC/0ixvvVAo4j3O1cj1iXAngm2VTVUa8Kfsyqq+qGqHo9rMhqD+1ZhTBRL8CYXPQNcIyKtvJuZ1wJPAYjIMSKyl4gIsBbXNLNVRPYVkX7eTcpNwEZvWypmAYeJyO4i0hS4qhqxPg30F5FTRKSeiLQQkS7etu+BPWrycyYjItuJyBki0lRVNxP+PRgTxRK8yUV/A6YDc4CPgZleGcDewERce/T7wP2qOgnX/n4r8AOuOWUn3A3YKqnqG8CzXn0zgFdTDVRVv8Y1lVwB/Ij7sOjsbX4U106+WkTGVPPnrMpZwGIRWQv8Bjgz1ZhN8RCb8MMYYwqTXcEbY0yBsgRvjDEFyhK8McYUKEvwxhhToHJqNMmWLVtqu3btanTs+vXr2X777dMbUEAs1uDkU7wWazCKLdYZM2b8oKqtfDeqas4sZWVlWlMVFRU1PjbTLNbg5FO8Fmswii1WYLomyKnWRGOMMQXKErwxxhSoQBO8iPzBm6Jsrog8IyIlQdZnjDEmLLCbrCKyK3AZcICqbhSR54AhwBNB1WmMCc7mzZtZunQpmzZtynYoSTVt2pQFCxZkO4yUVCfWkpIS2rRpQ/369VM+f9C9aOoBDUVkM260vpRGyjPG5J6lS5fSpEkT2rVrhxvrLTetW7eOJk2aZDuMlKQaq6qycuVKli5dSvv27VM+f2BNNKr6DfAv4GvgO2CNqk4Iqj5jTLA2bdpEixYtcjq5FyoRoUWLFtX+9hTYYGPe1GKjgVOB1cDzwChVfSpmv6HAUIDS0tKykSNH1qi+yspKGjduXPWOOcBiDU4+xZtvse66667stdde2Q6lSlu3bqVu3brZDiMl1Y31s88+Y82aNVFl5eXlM1S1u9/+QTbR9Ae+VDcVGSLyAtCbmPGu1c1dOQKge/fu2rdv3+rX9OabfH/33ZSOHg077FDLsIM3adIkavRzZkE+xQr5FW++xVpSUpIXTR+F2EQTUlJSQteuXVPeP8heNF8DPUWkkTc5wxFAMHc++vendOJEuPnmQE5vjMm+1atXc//999fo2MGDB7N69eqk+1x77bVMnDixRueP1a5dO3744Ye0nKs2gmyDnwqMwk1i8LFX14ig6gNg+fJAT2+MyZ5kCX7r1uQTWo0dO5ZmzZol3efGG2+kf//+NQ0vJwXaD15Vr1PV/VS1o6qepao/BVmfMaZwXXnllXz++ed06dKF4cOHM2nSJMrLyzn99NM58MADATjhhBM47LDD6NChAyNGhK8nQ1fUixcvZv/99+eiiy6iQ4cOHHXUUWzcuBGAc889l1GjRv2y/3XXXUe3bt048MADWbhwIQArVqzgyCOPpFu3blx88cW0bdu2yiv1O+64g44dO9KxY0fuuusuwI1Bc/TRR9O7d286duzIs88++8vPeMABB9CpUyeGDRtW699ZTg02ViNffpntCIwpPkH1pEnS6ePWW29l7ty5zJo1C3D3BaZNm8bcuXN/6Tr42GOPUb9+ferVq8dBBx3EySefTIsWLaLOs2jRIp555hkefvhhTjnlFEaPHs2ZZ8bPeNiyZUtmzpzJ/fffz7/+9S8eeeQRbrjhBvr168dVV13F+PHjoz5E/MyYMYPHH3+cqVOnoqocfPDBHH744XzxxRfssssujBw5kiZNmrBmzRp+/PFHXnzxRRYuXIiIVNmklIr8H6ogB9q5jDHZ0aNHj6h+4f/+97/p3bs3PXv2ZMmSJSxatCjumPbt29OlSxcAysrKWLx4se+5TzrppLh93n33XYYMGQLAwIEDad68edL43n33XU488US23357GjduzEknncTkyZM58MADmThxItdeey2TJ0+madOm7LDDDpSUlHDhhRfywgsv0KhRo2r+NuLlf4Kvk/8/gjF5RzWYpZoih9qdNGkSEydOZOLEicyePZuuXbv69htv0KDBL+t169Zly5YtvucO7Re5T3W7lSfaf5999mHGjBkccMABXHXVVdx4443Uq1ePadOmcfLJJzNmzBgGDhxYrbr85H92tARvTFFo0qQJ69atS7h9zZo1NG/enEaNGrFw4UI++OCDtMdwyCGH8NxzzwEwYcIEVq1alXT/ww47jDFjxrBhwwbWr1/Piy++yKGHHsq3335Lo0aNGDJkCMOGDWPmzJlUVlayZs0aBg8ezF133fVLU1Rt5H8bvCV4Y4pCixYt6NOnDx07dmTQoEEcffTRUdsHDhzIgw8+SK9evdh///3p2bNn2mO47rrrOO2003j22Wc5/PDDad26ddJ+7N26dePcc8+lR48eAFx44YV07dqV119/neHDhwPum8IDDzzAunXrOP7449m0aROqyp133ln7gBMNFJ+NpUYTfsyZE/6Cd8451T8+C4ptQoJMyqd48y3W+fPnZzuMlKxduzawc2/atEk3b96sqqpTpkzRzp071+p81Y3V79+AJBN+FNYV/JNPwuOPB3eH3xhT1L7++mtOOeUUtm3bxnbbbcfDDz+c7ZCSKqwED+5a3hK8MSYAe++9Nx999FG2w0hZ/jdg+yV4Y0wg1P5/ZU1NfveFl+AfeSQ7cRhT4EpKSli5cqUl+SxQbzz4kpLqTYpXeE00Dz4IF1+cnViMKWBt2rRh6dKlrFixItuhJLVp06ZqJ8JsqU6soRmdqqPwEvy2bdmJw5gCV79+/WrNJpQtkyZNqtaQutkUdKyF10RjCd4YY4BCSPCx5s3LdgTGGJMT8j/Bx16x2w0gY4wBCiHBVzHQvzHGFKv8T/DW5m6MMb7yP8H7Wb8+2xEYY0zW5X+C32uv+LLPPst8HMYYk2PyP8H7DRf888+Zj8MYY3JM/id4P3bj1RhjLMEbY0yhsgRvjDEFKrAELyL7isisiGWtiFweVH1RLMEbY0xwCV5VP1HVLqraBSgDNgAvBlVflH79YObMjFRljDG5KlNNNEcAn6vqVxmqDwKYcNcYY/KJZGLwfhF5DJipqvf6bBsKDAUoLS0tGzlyZPXPv2ULhx95ZFz5pIqK6gebAZWVlTRu3DjbYaQkn2KF/IrXYg1GscVaXl4+Q1W7+25MNBt3uhZgO+AHoLSqfcvKyqo1w3jM1OLxy/LlNT9fgCoqKrIdQsryKVbV/IrXYg1GscUKTNcEOTUTTTSDcFfv32egrmiXXJLxKo0xJldkIsGfBjyTgXriLViQlWqNMSYXBJrgRaQRcCTwQpD1JDR/vo0Pb4wpWoEmeFXdoKotVHVNkPUAVO6xh/+G114LumpjjMlJBfMk68d//7v/hjfeyGwgxhiTIwomwf+0007+G/xGmzTGmCJQ+Nnvrrtg3bpsR2GMMRlXWAm+Uyf/8pYtMxuHMcbkgMJK8Il6zNgEIMaYIlRYCd6u1I0x5heFleCvuSbxNusPb4wpMoWV4Js1S7ztkUcyFoYxxuSCwkrwLVok3vbcc5mLwxhjckBhJfi2bRNvq1s3c3EYY0wOKKwED3DUUf7lr78O27ZlNhZjjMmiwkvwDz6YeNuyZZmLwxhjsqzwEnz79om3WU8aY0wRKbwEb4wxBii2BG9X8MaYIlJcCf6//812BMYYkzHFleD/8pdsR2CMMRlTXAneGGOKSGEm+Ndeg4EDYfnybEdijDFZUy/bAQRi8GC3GGNMESvMK3hjjDGW4I0xplAFmuBFpJmIjBKRhSKyQER6BVlfSk44AaZOzXYUxhgTuKCv4O8GxqvqfkBnYEHA9VXtpZegZ89sR2GMMYELLMGLyA7AYcCjAKr6s6quDqq+avv222xHYIwxgRIN6PF9EekCjADm467eZwC/V9X1MfsNBYYClJaWlo0cObJG9VVWVtK4ceO48r7l5QmPef+55/ipVasa1VcbiWLNRfkUK+RXvBZrMIot1vLy8hmq2t13o6oGsgDdgS3Awd77u4Gbkh1TVlamNVVRUeG/wY1A479cf32N66uNhLHmoHyKVTW/4rVYg1FssQLTNUFODbINfimwVFVDdzRHAd0CrM9fspmcrr8eHnoIVq7MWDjGGJMpgSV4VV0GLBGRfb2iI3DNNZn19tvJt//mN3DiiZmJxRhjMijoXjSXAk+LyBygC3BLwPXF69MHevRIvs/kyZmJxRhjMijQoQpUdRauLT67RKreZ/NmqF8/+FiMMSZDiuNJ1r59q95np51gy5bAQzHGmEwpjgR//fVV77N6NaxYEXQkxhiTMcWR4EtKsh2BMcZkXHEk+FTZnK3GmAJiCT7SDTfYJCHGmIJhCT7SiBFQWprtKIwxJi2KJ8HPz/wzVsYYk03Fk+D339/a2I0xRaV4EnzIwoVV71NRAf/4B2zbFnw8xhgTkOJL8PvuC/ffDw0bJt6nXz+48ko49NDMxWWMMWmWUoIXkbYi0t9bbygiTYINK2CXXALr11e935QpwcdijDEBqTLBi8hFuKF+H/KK2gBjAowpM1IZn8YYY/JYKlfwvwX6AGsBVHURsFOQQWVMKkMT/Phj8HEYY0wAUknwP6nqz6E3IlIPKIzuKC1bVr3PKacEH4cxxgQglQT/toj8BWgoIkcCzwOvBBtWDnnzzWxHYIwxNZJKgr8SWAF8DFwMjAWuCTIoY4wxtVflhB+qug142FuK0+LF0K5dtqMwxphqqTLBi8iX+LS5q+oegUSUiw45BJYuzXYUxhhTLalM2Rc55V4J8Gtgx2DCyYKSEti0Kfk+33yTmViMMSaNqmyDV9WVEcs3qnoX0C/40DLkk09S3/eyy+Cgg9z8rcYYk+NSaaLpFvG2Du6KPr+fZI20++6p73vPPe71vfdSm+fVGGOyKJUmmtsj1rcAi4HC6hw+YwaUlWU7CmOMSatUetGUZyKQrOrWDY49Fl5J0r3/88/D65dfDrNmBR2VMcbUSsIELyJ/THagqt5R1clFZDGwDtgKbFHV7smPyKKqxorfa6/w+uzZ8OqrcMwxwcZkjDG1kOwma5MqllSVq2qXnE7usVK58XrssXD11cHHYowxNZTwCl5Vb8hkIFnXsaO7KgfYZ5/UjrnlFrjmmuRjyxtjTJaIVtE0ISIlwAVAB1w/eABU9fwqT+4eklqFe1DqIVUd4bPPUGAoQGlpadnIkSOrE/8vKisrady4cY2OBaizaRO7PfssK/r2ZUPbthw6aBB1q+ofD7wzbhzbSkqq3C9SbWPNpHyKFfIrXos1GMUWa3l5+YyELSSqmnTBDS52E/A5cA4wAbi7quO8Y3fxXncCZgOHJdu/rKxMa6qioqLGx/o6/HBV1zKffFm/PvuxBiifYlXNr3gt1mAUW6zAdE2QU1MZbGwvVf0rsF5VnwSOBg5M5ZNFVb/1XpcDLwI9UjkuJ1x1VWr7hSYO+e671GaJMsaYDEklwYce21wtIh2BpkC7qg4Ske1DU/uJyPbAUcDcGsaZeQMGwPlVtkI5K1bALrtAaWmwMRljTDWkkuBHiEhz4K/Ay8B84B8pHFcKvCsis4FpwGuqOr7GkWbDH5P2FHX69oW53ueWXcEbY3JIKk+yPq6qW4G3gZRHkFTVL4DONQ0sJ3ToUPU+06bBkiXh9z/9BA0aBBeTMcakKJUr+C9FZISIHCFiM1X7ev758Pof/pC9OIwxJkIqCX5fYCJu8u3FInKviBwSbFg55I03qt4n1H8e4IEH4MMPYdu24GIyxpgUpDJc8EZVfU5VTwK6ADvgmmuKwxFHVP+YHj3gzjvTH4sxxlRDKlfwiMjhInI/MBP3sFNhjSaZjAhccEH4/d/+ltpxjzwSTDzGGJOiKhO89zTq5cBkoKOqnqKqo4MOLKe0aRNeP/307MVhjDHVkEovms6qujbwSHLZ8OHw9ddw6qnQvj1MmQK9eyc/xu5HG2OyLJXx4Is7uQNsvz089lj4fa9eVR+zYEFw8RhjTApSaoM3NbRqlXudORO+/z67sRhjio4l+CCdfz68/babDnDnneH99+Htt+k5ZAi89Va2ozPGFLhUbrL+XkR2EOdREZkpIkdlIri8N2YMjB0bfn/LLdC/PyXff1+z7pfGGFMNqVzBn++1wx8FtALOA24NNKp88MILqe13223hdRHYujWYeIwxJkYqCT7UHWQwblya2RFlxevEE6t/zCuvVD33qzHGpEkqCX6GiEzAJfjXvSGA7Tn8dLDhDIwxAUolwV8AXAkcpKobgPq4ZhpTW4cemu0IjDEFLJUE3wv4RFVXi8iZwDXAmmDDKhJTpoRf99wT3nwzu/EYYwpKKgn+AWCDiHQG/gR8Bfwn0KiKyfz5MHgwfPEF9O+f7WiMMQUklQS/xZvY9XjcZNt3A02CDStPHXNM9Y/p0AE2b656P2OMqaZUxqJZJyJXAWcBh4pIXVw7vIn03XfQvDmUlGQ7EmOMAVK7gj8V+AnXH34ZsCvwz0Cjyhcvvhhe33nn9E7Vt2lT+s5ljClKqUz4sQx4GmgqIscAm1TV2uABDj/cvfbrV7vzbNgQ/X7hQmjYEC6+uHbnNcYUtVSGKjgFmAb8GjfRx1QR+VXQgeWF5s1h40aYODG9533gAfc6YkR6z2uMKSqptMFfjesDvxxARFrh5mgdFWRgecPa3I0xOSqVNvg6oeTuWZnicQCISF0R+UhEXq167wJw993ZjsAYY4DUruDHi8jrwDPe+1OBsUn2j/V7YAFusu7Cd9llbvan22+v+Tk++SR98RhjilYqN1mHAyOATkBnYISq/jmVk4tIG+BooLhmoP7Xv2p3vE0OYoxJA9EARzcUkVHA33EPRg1T1bgngURkKDAUoLS0tGzkyJE1qquyspLGjRvXItr0aj59Op2HD6/2cZPeeou+Eb1yJlVUpDOsasu132tV8ileizUYxRZreXn5DFXt7rtRVX0XYB2w1mdZB6xNdFzE8ccA93vrfYFXqzqmrKxMa6qioqLGxwZi2TJVNzhw9ZYPPoh+n2U593utQj7Fa7EGo9hiBaZrgpyasA1eVWs7HEEf4DgRGQyUADuIyFOqemYtz5sfSktrdtxzz6U3DmNM0QpsTlZVvUpV26hqO2AI8FbRJPfaqKxM/t4YY1Jkk27nmtiHm2Kv6JctczdxV63KXEzGmLyUkQSvqpPU5wZrUenWrWbHXXABzJgRfj9gAAwfDjvumJ64jDEFy67gg9SrV3j9jTdqfp7uETfI58xJvN/kyW6u2O++q3ldxpiCYQk+SE8/7a6433vPXXE/9VSw9R12GIwZA5dcEmw9xpi8YAk+SO3bw/jx0Lu3e/+rWo7RNmFCavstXly7eowxBcESfCY1aAC77RZd9t//pn58smaen38Or9tY8sYYLMFnXosW4fXevaFu3dSPXb06+v22beH1e+4Jr9tYNsYYLMFnXuTQEH/4Q3TCT+a77+CRmCF91q4Nr8+dW/vYjDEFxRJ8pkUm+F/9Co48Es49t+rjjj8+vmzZsrSFZYwpPJbgM22//dzrdtu5V5HURp/88MP4sqFD0xeXMabgWILPtPvuY+lJJ8FHH9X+XJMn1/4cxpiCZQk+01q25LNLL4UDDgiXRd4sraknnqj9OYwxBcUSfC6ozZj8gwfDokXx5TZWjTFFL5Up+0zQajOuzLhx/jNA7bhj7T44jDF5z67gc0G9evDttzU/fubMxNu2boXzzrMmHGOKkCX4XNG6dfT7Vq3Sc97XX3fJ/bzzoDrT/23bBkcfTbvHHktPHMaYjLMEn6smTIBrrqn9edavD6/36wf33pvacVOnwtixtKvOUArGmJxiCT6X3HhjeL19e9dHvjY2b46/2XrppfDNN1Ufu2VL7eo2xmSdJfhc8te/htcbNKh9gv/mG7j44vjy0aOrPnbMmNrVbYzJOkvwueaDD2DSJCgpqf252rf3Lx8+PLz+5ptwwgmwfHn0PnfcUfv6jTFZZd0kc83BBwdfR+TQwv37u9emTeHJJ4Ov2xiTMXYFn8v8mlfSKfJKfsGCYOsyxmScJfhctssusGRJfPlf/lL7c0+ZEj3Imd9gZsaYvGYJPte1aeMm0o4UGpGyNvr0iS97773an9cYkzMsweeDF16AOXOgZ0/4+GP3dGoiqQw9nMghh9T8WGNMzgkswYtIiYhME5HZIjJPRG4Iqq6icOCB8P770LFj8tEn27atXT2PPQZ77RVd9uCDtTunMSYrgryC/wnop6qdgS7AQBHpGWB9xaNly8Tb6tTyn/SCC+Dzz6PLLrkkvP7yy7D//rD99rB4cfR+qq6bZ23G1THGpE1gCV6dSu9tfW+x4Q3T4Zhj4Mor/bfV9uGoRJYuda/HHw8LF8KGDTBgQPQ+v/oV9OoFu+4aTAzGmGoRDXBIWRGpC8wA9gLuU9U/++wzFBgKUFpaWjZy5Mga1VVZWUnjxo1rEW3mpCvWvuXlcWVzb7qJjpFPxKbRpIqKuDrfe+EFNjdvTsMlSzj47LOj9s2GYvw7yASLNRjpiLW8vHyGqnb33aiqgS9AM6AC6Jhsv7KyMq2pioqKGh+baWmL1TWKhJcPP1R96aX48nQtt98eXzZsmIulT5/o8kirVqnusYfq9den5+dOoij/DjLAYg1GOmIFpmuCnJqRXjSquhqYBAzMRH1F48ILo9937w6HHhpcfVdcEV8W6rWzdm3i4x59FL74Aq6/Pn4Skv/8By6/3CYnMSYAQfaiaSUizbz1hkB/YGFQ9RWlhx8Or++/v3tt3jw7sSQbfTIyeXftGv3+nHPg7rvhlFOCi82YIhXkFXxroEJE5gAfAm+o6qsB1lfcevdOvn2//WCHHYKpWzV+qIPzzguvR/a2mT0b1q2LP8eoUYGEZkwxC7IXzRxV7aqqnVS1o6reWPVRptrefRfOPBP+8Y/k+916K6xeHUwMfsn5iSfC3SXvuy96W6KePtZMY0xa2ZOs+a5PH/jvf6FFi3DZjz/G77fDDsF1oUzUvPLVV/7l06f7bz/mmPTFZIyxBF+Q/Nrhs3F1fNFF/uXjxrnXL7+MLh87NrXzqsIf/+hu3hpjErIEXyxCCf6hhzJX57x50U/BxkrW8yaZ2bPhzjvjexEZY6JYgi8WTZu61/PPz2y9fuPY/POfMH++eyo2Vuw3jT/+0fWyibRhQ3g9UTOQMcYSfNHo7j3oVrdu/LZkV9lB6dDBv/zWW8Prixa5K/XLL098nnbtot7u8vLLbpycL76odYjG5DtL8IXqiSf8y2NvtF53Hdx/v7tSzgWhyUyWLIF99gmX3357eN3vJrJ3zD533umu8PfcM7X6xo1zwzDHDrAG7kPizDNttiuTtyzBF6pzzolOkImEet8E1cOmpkIPboUMG+Zely2DY4+N3vb99+71jDOiy2fOrLqewYNh6lT4zW/it510Ejz9NPTrl1rMxuQYS/CFrG9f95qoOQRgyBD3GkqgkbJ1Vf/FF7B+vf+2V16JLzv1VPf6ySfR5U8/nXqdEyfGl4Wu6pctS/08xuQQS/CF7Pbb3UNGscnrxohnzkIj2e28c/zxAwbwxYUXuhmlMmnWLP/ylSv9v2m8/bb7gFq+PLr8jjtcE8yPP8K++8K990Lr1vD3v/ufP3Yc+8i6/GJ69FH3BHFQD5AZU0uW4AtZ48bwf/8Xn7z/+lc46yz47W+hYcPEx9ety9dnnBE/JyzAqwGOOjF8uH/5SScl7s8f2UYf6e67XTPUp5/CpZe6q/FEk5ZH3uCF6CEVnnoqfv8LL3SzbN15p//5jMkyS/DF6j//cVe0kQYNin6faHaoX/8amjULJCwgcQ+Yd96Jj7kqr7/uXz5hQnzZokWJzxPb/HP//eH1n34Kr48fD1df7T+t4pYt4YlTjMkAS/Am7LXXot8nulr+73/d3LDZMGdOes7zz3/Gl40fD5s3++8f2Vyj6r79+Bk0CG65Jf53CXDkkbDbbjBlSvXjNaYGLMGbMBG4+ebw+0aNwuuR7fYNGrgHp/K57Xn5cti6Nb589WrXHPPNN9Hln30WXk/UHBQ5ZPJxx7mxdSI/JCdNcq/PPut//ObN8Pzz8MMPVUVvTEoswZtoke3Tu+wSXu/VK37f0NOxkc48M/0xBWHOHP+xbx54wN2f2Hff6PJQX/ht2xLfI4gdBvm118IfFFOnVh3THXe4gduCnLTFFBVL8Cbe7NmuuWL33cNlffu65ZprEh+3datrvvFr/oDwFWyuOO64+LL33nOvibpp+o1lH+q94zdkc6gt/vDDw2X//rf/uUMTqS9MYV6cN9909ySCtnUrvP8+8vPPwddl0s4SvInXqRMMGBBdVq8eVFTATTdFl4dGdPzyy/BN2WHD/B8y6tLFv75E3Razwe/ma8j55/vPXPX44y4RJkvwkTdiIXoM/bfe8h+zJ1JkU8/PP0P//u5Dw2/AtbVr3Y3wt9+O37Zpk//5P/jAfYDPmxddfvPN0Ls3+912W/wxy5a5XlqpfCCZrLAEb2rn/PNd8okZE4auXaPfN2ni36QDsOuugYSWdo8/7gZJ83P99f7lfu384BJwyBFH+I8HNGuWG3L5wAPdh2foij3yRvCjj8Ibb4Tf//CD+z2PGuUSduiDZcUKd4+lYUP3c8Tq1ct9IJx8cnS5Ny1k6Ztvxh9z7rmuSauq2cRM1liCN8GJTIbJnordccfgY0mXww7zL0904/WWW/zHuQF2TTZNYatW7kPykUdg7lxXdvjhrk0/tgvmUUeF12Obwc49171G9vpJNqLoqlXR7yNH7oxtWgrdl4g9JhHV9N9AtlnAkrIEb4Kz//4usZ9+erjtvlOn+P0GDXLdBxNJkCD5v/+rfYzpsnGjf/ljj8Fee/lu2vu++6Cy0v+4RImwTRv/cfTHj3evFRXR5SNHutfIXkAQ32QUEtmEs2FD9MBuv/99eP3HH+Hrr/3PkcgFF7gPLpHq34/xS+TPP+++2fztb9U7VxGxBG+CdfvtbkyYevXc+/ffd1elkerUSZwsTjwR9tjDf1vsXK/5qEmT6h8TOxMWhHsvPfCA/zGxD62VlIT79kcm7sgPj08/TRxDop5EkSI/RDZujG4aKi+v+viQceNc19zYp6dDU0X+9a9uGIsQVbj44sS/iyJiCd5kVqNG7krugw/c+7feCm+L7XsOif+TVvfqsZD4daNcudIltkRNFslmz4ptennrLXjpJf+ncUM3VGOf+o2s9/XXoazMfYiEHkzzG8wt1kUXuQ+d2G88gwe7+w6xo4hGirhR32TBAhgxwn3DC83/m2kffRR9byRSoh5aAbAEb7Lj4INdUoi8kttll/imhNJS/+NDN2YvvTR+W+fO1R/SoBBE3riNlWgYhhUr4suOOAJOOMF/3P0xY9zr5MnR5aF7EBs3wsCB4V5UnTu71/r1E8cG7kMh9M0uskkuURNWrNtvh+++g82b2T7yw/+gg1I7vjbGjnXfoCK7knbr5u6NxH6wPfWUGyPqnnuCj4sAE7yI7CYiFSKyQETmicjvqz7KFL0990zc2yZSqMnhrruiir/v18/1Pkk0lEAqDxzlq9Gj/cuTDQyX7JvQiy/Gl/38M3z8cXx5qMkm8qZsiKp/gg9d9c+b5z4UIoV6H8V+UHfqlLgn029/C9ttx36x3VVjv9X8/e/um0LkfkuXuq6nJ5wQ/Y1myxbX86hZs/D9ibFj3b2O5cvdeY4+2jVDhp78jvwmeuSR0XWfdZZ7vewy/58h3VQ1kAVoDXTz1psAnwIHJDumrKxMa6qioqLGx2aaxVqFadNcY8Mxx4TLwg0QbokUUb70+OPD5QsWRB/zn//4nwtUJ0zwLz/qKP/yQllGj67e/ldfrTpypP+2gw5y22PL335bddKk+PIlSxL/ezz8cOJtPXok3ua3fPVV+G/i2Wf9/44S/X117hxdvn59eP3yy/2Piz0mwd+qanr+fwHTVRPk4UQb0r0ALwFHJtvHEnzuyVqsy5erbt0afn/ffYn/0zzyyC/lH19/ffS2E08MH/Ptt65s8OD4/5hbt/onh/ffr14CtMV/OfbY+LIlS1TPPtt///793b+V37a99lJ9/vnU6x40KPz3ELstUXnoby+2/LXXktfld8ycOQnrWTB8eM3/j/xyysQJXtz2YIlIO+AdoKOqro3ZNhQYClBaWlo2MtStq5oqKytpHJq8IsdZrDXT4+yzabRkCT83a8aUmOaDemvX0vizz1i69940juiZUuenn2jz/PNs2H13fvD6sNdfvZo+EWPcrzjkEObddBN9fXp2TH/wQbr7TOe39MQTabRkCTtm6yZeEZjy/PP0TnZfoRreGTeONqNHs0dMD653xo1jW0lJ3L/91pISpj35JL1Cs4V5VnfqRLMkI5pOqqjw/Tua5HVfTbatpsrLy2eoanffjYkyf7oWoDEwAzipqn3tCj735FSs336r+rvfqX76acJdUo63QYPwldSqVa7suOPir76mT/e/Urv5ZhdHoiu53r39yy+9tHZXwrakf1H1L//Tn6p/rkTfBEPNjYnqrwWSXMEH2otGROoDo4GnVTXD876ZgtO6tet9sPfetT9Xgwbh9dDkJX43KXfe2X9Qr06dXByhsXgi3XEHXHedf7233w6nnVbtcH0lGh7BVE9okLdYybqWJlK3rn/5q69G99WP5De+UZoE2YtGgEeBBap6R1D1GFMjY8a43jqhbn/gHsaKnc5v112hT5/osj/9yfWcADjvvPhzX3yx6ybnp359+N//XD/tWH/+c3xZsg8zv7pDEg3sdvXViY8pVn6DxEHVA8BV14cf+pcHOOdxkFfwfYCzgH4iMstbBgdYnzGpKy93Y6gcf3x0+d/+5oY8LiuDJ55wZXXquGGEb7oJHnrIJYTQU6Ai8X33GzWCli1dv+xIRxwRXo/sM92hg5vwO3agL3BPk27ZApdfHr8tcjjnWIMT/Fe74orEx/jVYdIn9ORtrFNPdX3/Ew1MVxuJ2m6ysVgbfO7Jp1hVsxhv9+7+baqRba2bN4fLV63Sja1aqQ4bFi7butW11Yb2P+208LYnnvBvu33xRf923cjufLHH7LZb4m233RZfPn68Tpo4MTvt48W0zJ9foz89stUGb0zRmDrVta3HPqF47bXh9dB4PADNmvHBs89GT45Spw688or7775li2vKCTnrLDd07xlnRJ//hBPihxS44Ybo6RZjffFF4knT/caYGTAArVsX/MaE95sApaZU03eufJSo/b4WLMEbkw516riE/LvfRZdffbX7Cv7MM/HHRE7kHSv2P3udOm5yD7+2dZHwkMs77hi+aZhoYvR69eK33XJLeD3R062xyf/RR91j94nakBM9cfrVV/7lEN10FSn2PkikyBvmke680788WxPGV8USvDF5Zrvt3JC9Q4ak53znnw/9+rlH4yNNn+6+DSxZ4uoEN2RDot48sePzR76PHLo5Nul8/LFLnFu2hMeVP/FE95h/yM8/u/sP++8f/S0EXHy775548LFEY9YkmubwnnvcEAKR9zdCEt1T+PhjN0JlrGQfPJE342O9/LJ/eezsZ1WJHfEzHRK13WRjsTb43JNPsarmV7wZizXU9/6ll6LLp05Vfewx1Y0b44+54gr3rID39G+VsX7wgavj5pvjt23apHr++apjxkSXb9umOm6catu2qjNnhstjhxPYbTdXvmWL6nnnRW9buzZ8XGR5u3bh8nHjorf57Q+q69bF7xt5jF/5fvsl3qaa+InbkpL4spUrk/+OEyAXhipIZbEEn3vyKVbV/Io3Y7Fu26a6YkWtTpFSrD/9VKs6okyZEk58kWPJbN7sn6xVwx8yoHrLLdHbpk9X7dbNfaiF/PBD+OZ4gwbh8q1bVYcMCZ9rwABX/tFH0XWffbb78PLbluyDZMAA92+yaJFuiXzgroaSJXhrojGm0Im4bptBCzUNpUOvXuGUGNkdtF698INisW3/Bx8cHkY6sskIXLfXGTOgR49wWYsWrm/62rXRM1mF7qecc45r5gk153Tp4uLZts11sX3yyXD7f5cu0bNpRdYTO0Xigw/+Mu795PHj3Vj3QXSRBOpVvYsxxuSQ//0vvm0/ZN48Phw1ioOqMw6836xaIuHnIPy2+fVC6tvXTXDywgsQOX7RvfdCz57u4badd4a2baOPqxdcGrYEb4wpHE2bsn7PPbNX/4EHuiVSw4ZutqqLLsp4ONZEY4wxBcoSvDHGFChL8MYYU6AswRtjTIGyBG+MMQXKErwxxhQoS/DGGFOgLMEbY0yBEjeUQW4QkRVAkiHdkmoJ/JDGcIJksQYnn+K1WINRbLG2VdVWfhtyKsHXhohMV9Xu2Y4jFRZrcPIpXos1GBZrmDXRGGNMgbIEb4wxBaqQEvyIbAdQDRZrcPIpXos1GBarp2Da4I0xxkQrpCt4Y4wxESzBG2NMgcr7BC8iA0XkExH5TESuzFIMj4nIchGZG1G2o4i8ISKLvNfmEduu8uL9REQGRJSXicjH3rZ/i4gEEOtuIlIhIgtEZJ6I/D5X4xWREhGZJiKzvVhvyNVYI+qpKyIficireRDrYq+eWSIyPZfjFZFmIjJKRBZ6f7u9cjjWfb3faWhZKyKXZyXeRJO15sMC1AU+B/YAtgNmAwdkIY7DgG7A3Iiy24ArvfUrgX946wd4cTYA2nvx1/W2TQN6AQKMAwYFEGtroJu33gT41Isp5+L1ztvYW68PTAV65mKsETH/Efgf8Gou/x149SwGWsaU5WS8wJPAhd76dkCzXI01Ju66wDKgbTbiDewHy8Ti/eCvR7y/CrgqS7G0IzrBfwK09tZbA5/4xQi87v0crYGFEeWnAQ9lIO6XgCNzPV6gETATODhXYwXaAG8C/Qgn+JyM1Tv3YuITfM7FC+wAfInXKSSXY/WJ/SjgvWzFm+9NNLsCSyLeL/XKckGpqn4H4L3u5JUninlXbz22PDAi0g7oirsyzsl4vSaPWcBy4A1VzdlYgbuAPwHbIspyNVYABSaIyAwRGZrD8e4BrAAe95q/HhGR7XM01lhDgGe89YzHm+8J3q89Ktf7fSaKOaM/i4g0BkYDl6vq2mS7+pRlLF5V3aqqXXBXxz1EpGOS3bMWq4gcAyxX1RmpHuJTlum/gz6q2g0YBPxWRA5Lsm82462HawJ9QFW7AutxTRyJ5MLvFhHZDjgOeL6qXX3K0hJvvif4pcBuEe/bAN9mKZZY34tIawDvdblXnijmpd56bHnaiUh9XHJ/WlVfyPV4AVR1NTAJGJijsfYBjhORxcBIoJ+IPJWjsQKgqt96r8uBF4EeORrvUmCp9+0NYBQu4edirJEGATNV9XvvfcbjzfcE/yGwt4i09z4thwAvZzmmkJeBc7z1c3Bt3aHyISLSQETaA3sD07yvbOtEpKd3p/zsiGPSxjv3o8ACVb0jl+MVkVYi0sxbbwj0BxbmYqyqepWqtlHVdri/w7dU9cxcjBVARLYXkSahdVxb8dxcjFdVlwFLRGRfr+gIYH4uxhrjNMLNM6G4MhtvkDcYMrEAg3E9QT4Hrs5SDM8A3wGbcZ+6FwAtcDfcFnmvO0bsf7UX7ydE3BUHuuP+k30O3EvMTaU0xXoI7mveHGCWtwzOxXiBTsBHXqxzgWu98pyLNSbuvoRvsuZkrLh27dneMi/0fyeH4+0CTPf+FsYAzXM1Vq+eRsBKoGlEWcbjtaEKjDGmQOV7E40xxpgELMEbY0yBsgRvjDEFyhK8McYUKEvwxhhToCzBm4IhIlO813Yicnqaz/0Xv7qMyWXWTdIUHBHpCwxT1WOqcUxdVd2aZHulqjZOQ3jGZIxdwZuCISKV3uqtwKHeWNx/8AYs+6eIfCgic0TkYm//vuLGxv8f8LFXNsYbfGteaAAuEbkVaOid7+nIusT5p4jM9cbtPjXi3JMkPIb506GxvEXkVhGZ78Xyr0z+jkxxqZftAIwJwJVEXMF7iXqNqh4kIg2A90RkgrdvD6Cjqn7pvT9fVX/0hkb4UERGq+qVIvI7dYOexToJ95RlZ6Cld8w73rauQAfc+CHvAX1EZD5wIrCfqmpoKAZjgmBX8KYYHAWcLW7Y4am4R8b39rZNi0juAJeJyGzgA9wAUHuT3CHAM+pGvfweeBs4KOLcS1V1G25IiHbAWmAT8IiInARsqOXPZkxCluBNMRDgUlXt4i3tVTV0Bb/+l51c231/oJeqdsaNg1OSwrkT+SlifStQT1W34L41jAZOAMZX4+cwploswZtCtA43HWHI68Al3jDJiMg+3giKsZoCq1R1g4jsh5seMGRz6PgY7wCneu38rXDTN05LFJi4cfibqupY4HJc844xgbA2eFOI5gBbvKaWJ4C7cc0jM70bnStwV8+xxgO/EZE5uFH9PojYNgKYIyIzVfWMiPIXcdOrzcaN0vknVV3mfUD4aQK8JCIluKv/P9ToJzQmBdZN0hhjCpQ10RhjTIGyBG+MMQXKErwxxhQoS/DGGFOgLMEbY0yBsgRvjDEFyhK8McYUqP8H9kNU/eIfLXgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, losses = train3(balanced_image_path, balanced_label_path, max(label_path)+1, 40)\n",
    "plot_losses3(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "overall_model = SEDense18_IBN().cuda()\n",
    "overall_model.load_state_dict(model.state_dict())\n",
    "torch.save(overall_model.state_dict(), \"SE18_IBN_balanced_checkpoint.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}